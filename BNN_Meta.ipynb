{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BNN Meta.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chedlyba/birdclef/blob/master/BNN_Meta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxPqD9xjb80w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import tensor\n",
        "from torchvision.datasets import MNIST\n",
        "import math \n",
        "from torch import nn\n",
        "from collections import OrderedDict\n",
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def binarize(tensor):\n",
        "    return tensor.sign()\n",
        "\n",
        "class BinarizeLinearLayer(nn.Linear):\n",
        "    def __init__(self, is_input=False, *kargs, **kwargs):\n",
        "        super(BinarizeLinearLayer, self).__init__(*kargs, **kwargs)\n",
        "        self.is_input = False\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        if not self.is_input:\n",
        "            input.data = binarize(input.data)\n",
        "        if not hasattr(self.weight, 'org'): \n",
        "            self.weight.org = self.weight.data.clone() \n",
        "        self.weight.data = binarize(self.weight.org)\n",
        "        out = nn.functional.linear(input, self.weight)\n",
        "        if self.bias is not None:\n",
        "            self.bias.org = self.bias.data.clone()\n",
        "            out+= self.bias.view(1, -1).expand_as(out)\n",
        "        \n",
        "        return out\n",
        "  \n",
        "class BinarizeConv2d(nn.Conv2d):\n",
        "\n",
        "    def __init__(self, *kargs, **kwargs):\n",
        "        super(BinarizeConv2d, self).__init__(*kargs, **kwargs)\n",
        "        self.is_input = False\n",
        "\n",
        "    def forward(self, input):\n",
        "        \n",
        "        if not self.is_input:\n",
        "            input.data = binarize(input.data)\n",
        "        if not hasattr(self.weight,'org'):\n",
        "            self.weight.org=self.weight.data.clone()\n",
        "        self.weight.data=binarize(self.weight.org)\n",
        "\n",
        "        out = torch.nn.functional.conv2d(input, self.weight, None, self.stride,\n",
        "                                   self.padding, self.dilation, self.groups)\n",
        "\n",
        "        if not self.bias is None:\n",
        "            self.bias.org=self.bias.data.clone()\n",
        "            out += self.bias.view(1, -1, 1, 1).expand_as(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class SignActivation(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, i):\n",
        "        result = i.sign()\n",
        "        ctx.save_for_backward(i)\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        i, = ctx.saved_tensors\n",
        "        grad_i = grad_output.clone()\n",
        "        grad_i [ i.abs() > 1.0 ] = 0\n",
        "        return grad_i"
      ],
      "metadata": {
        "id": "pwIZZqJdcu6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Adam_meta(torch.optim.Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), meta = {}, eps=1e-8,\n",
        "                 weight_decay=0, amsgrad=False):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        defaults = dict(lr=lr, betas=betas, meta=meta, eps=eps,\n",
        "                        weight_decay=weight_decay, amsgrad=amsgrad)\n",
        "        super(Adam_meta, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(Adam_meta, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('amsgrad', False)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
        "                amsgrad = group['amsgrad']\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                    if amsgrad:\n",
        "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
        "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                \n",
        "                if amsgrad:\n",
        "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    grad.add_(group['weight_decay'], p.data)\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                if amsgrad:\n",
        "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
        "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
        "                    # Use the max. for normalizing running avg. of gradient\n",
        "                    denom = max_exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                else:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "\n",
        "\n",
        "                bias_correction1 = 1 - beta1 ** state['step']\n",
        "                bias_correction2 = 1 - beta2 ** state['step']\n",
        "                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n",
        "                \n",
        "\n",
        "                binary_weight_before_update = torch.sign(p.data)\n",
        "                condition_consolidation = (torch.mul(binary_weight_before_update, exp_avg) > 0.0 )   # exp_avg has the same sign as exp_avg/denom\n",
        "\n",
        "                #decayed_exp_avg = torch.where(p.data.abs()>group['meta'], torch.zeros_like(p.data), exp_avg)\n",
        "\n",
        "                if p.dim()==1: # True if p is bias, false if p is weight\n",
        "                    p.data.addcdiv_(-step_size, exp_avg, denom)\n",
        "                else:\n",
        "                    decayed_exp_avg = torch.mul(torch.ones_like(p.data)-torch.pow(torch.tanh(group['meta']*torch.abs(p.data)),2), exp_avg)\n",
        "                    #p.data.addcdiv_(-step_size, exp_avg , denom)  #normal update\n",
        "                    p.data.addcdiv_(-step_size, torch.where(condition_consolidation, decayed_exp_avg, exp_avg), denom)  #assymetric lr for metaplasticity\n",
        "                    \n",
        "        return loss"
      ],
      "metadata": {
        "id": "bb5fQp9CdDP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(data_path):\n",
        "    with open(data_path, 'r') as fp:\n",
        "        data = json.load(fp)\n",
        "    # extract inputs and tagets\n",
        "\n",
        "    X = torch.from_numpy(np.array(data['spectrogram']))\n",
        "    y = data['bird']\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def get_data_split(data_path):\n",
        "    X, y = load_dataset(data_path)\n",
        "    labels= pd.unique(y).tolist()\n",
        "    l = []\n",
        "    for birds in labels:\n",
        "        for bird in birds.split(' '):\n",
        "            l.append(bird)\n",
        "    labels = pd.unique(l).tolist()\n",
        "        \n",
        "    # create train/validation/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "    X_train = torch.swapaxes(X_train, 1, -1)\n",
        "    X_validation = torch.swapaxes(X_validation, 1 ,-1)\n",
        "    X_test = torch.swapaxes(X_test, 1, -1)\n",
        "\n",
        "    return X_train, X_validation, X_test, y_train, y_validation, y_test, labels\n",
        "\n",
        "\n",
        "def normalize(tensor):\n",
        "  tensor_norm = tensor - tensor.mean()\n",
        "  return tensor_norm / (tensor_norm.abs().max() + 1e-7)\n",
        "\n",
        "\n",
        "class SoundDS(Dataset):\n",
        "    def __init__(self, x, y, mappings, is_train=True, augment=1):\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        augmented_data = []\n",
        "        augmented_data_labels = []\n",
        "        \n",
        "        for data, label in zip(x, y):\n",
        "          data = normalize(data)\n",
        "          self.x.append(data)\n",
        "          self.y.append(label)\n",
        "          if is_train:\n",
        "            if label != 'nocall': \n",
        "              for _ in range(augment):\n",
        "                  new_data = (data + torch.unsqueeze(torch.randn(data.shape[1], data.shape[2])-torch.mean(data), 0))\n",
        "                  augmented_data_labels.append(label)\n",
        "                  augmented_data.append(new_data)\n",
        "              \n",
        "        self.x += augmented_data\n",
        "        self.y += augmented_data_labels\n",
        "\n",
        "        self.mappings = mappings\n",
        "        self.num_classes = len(mappings.keys())\n",
        "        print(f'Total items: {len(self.x)}')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        target = self.mappings[self.y[idx].split()[0]]\n",
        "        return self.x[idx] , target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n"
      ],
      "metadata": {
        "id": "e-60dxTYd1I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model, val_dl):\n",
        "    correct_pred = 0\n",
        "    total_pred = 0\n",
        "    preds = np.empty(shape=(1,))\n",
        "    targets = np.empty(shape=(1,))\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in val_dl:\n",
        "            inputs, labels = data[0].float().to(DEVICE), data[1].long()\n",
        "            outputs = model(inputs).to('cpu')\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            _, prediction = torch.max(outputs,1)\n",
        "            correct_pred += (prediction == labels).sum().item()\n",
        "            \n",
        "            total_pred += prediction.shape[0]\n",
        "            \n",
        "            preds = np.append(preds, prediction)\n",
        "            targets = np.append(targets, labels)\n",
        "    preds = preds[1:,...]\n",
        "    targets = targets[1:,...]\n",
        "    acc = correct_pred / total_pred\n",
        "    print(f'Accuracy: {acc:.2f}, Loss: {loss:.2f}, Total items: {total_pred}')\n",
        "    return preds, targets, acc\n",
        "\n",
        "def train(model, train_dl, test_dl, lr=5e-03, epochs=50, optim='', meta=0.0, weight_decay=1e-07):\n",
        " \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if optim == 'meta':\n",
        "        optimizer = Adam_meta(model.parameters(), lr=lr, meta=meta, weight_decay=1e-07)\n",
        "    else :\n",
        "        optimizer = torch.optim.Adam(model.parameters(),weight_decay=weight_decay)\n",
        "    \n",
        "    \"\"\"scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr= 0.005,\n",
        "                                                   steps_per_epoch=int(len(train_dl)),\n",
        "                                                   epochs=epochs,\n",
        "                                                   anneal_strategy='linear') \"\"\"\n",
        "    loss_vec = []\n",
        "    acc_vec = []\n",
        "    test_acc = {}\n",
        "    weights = {}\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct_prediction = 0\n",
        "        total_prediction = 0\n",
        "        start = datetime.now()\n",
        "        model.train()\n",
        "        for i, data in enumerate(train_dl):\n",
        "\n",
        "            inputs, labels = data[0].float().to(DEVICE), data[1].long().to(DEVICE)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            \n",
        "            for p in model.parameters():  # updating the org attribute\n",
        "                if hasattr(p,'org'):\n",
        "                    p.data.copy_(p.org)\n",
        "                    \n",
        "            optimizer.step()\n",
        "\n",
        "            for p in model.parameters():  # updating the org attribute\n",
        "                if hasattr(p,'org'):\n",
        "                    p.org.copy_(p.data)\n",
        "            \n",
        "            #scheduler.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, prediction = torch.max(outputs, 1)\n",
        "\n",
        "            correct_prediction += (prediction == labels).sum().item()\n",
        "            total_prediction += prediction.shape[0]\n",
        "\n",
        "            if i % 100 == 0 and i !=0:  \n",
        "                print(f'[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
        "                print(f'{datetime.now()-start}')\n",
        "                start = datetime.now()\n",
        "        if epoch % 10 == 0 :\n",
        "          ew = model.save_weight()\n",
        "          for l in ew.keys():\n",
        "            if l not in weights.keys():\n",
        "              weights[l] = []\n",
        "            weights[l] += ew[l]\n",
        "\n",
        "        num_batches = len(train_dl)\n",
        "        avg_loss = running_loss/num_batches\n",
        "        acc = correct_prediction/total_prediction\n",
        "        acc_vec.append(acc)   \n",
        "        loss_vec.append(avg_loss)\n",
        "        print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
        "        for i, dl in enumerate(test_dl):\n",
        "          _, _, acc = inference(model, dl)\n",
        "          if str(i) not in test_acc.keys():\n",
        "            test_acc[str(i)] = []\n",
        "          test_acc[str(i)].append(acc)\n",
        "\n",
        "    return loss_vec, acc_vec, test_acc, weights"
      ],
      "metadata": {
        "id": "qo6mjMOUmu_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioClassifierBNN(nn.Module):\n",
        "\n",
        "    def __init__(self, init='uniform', width=0.1, n_labels=10, n_channels=1, dropout=0):\n",
        "        super(AudioClassifierBNN, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.hidden_layers = 4\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.n_labels = n_labels\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.layer_list = [\n",
        "            # ( ('cv1', BinarizeConv2d(self.n_channels, 64, kernel_size=(5, 5), stride = (2, 2), bias=False, padding=(2 ,2))) ),\n",
        "            # ( ('bn1', nn.BatchNorm2d(64)) ),\n",
        "            # ( ('cv2', BinarizeConv2d(64, 128, kernel_size=(3, 3), stride = (2, 2), bias=False, padding=(2 ,2))) ),\n",
        "            # ( ('bn2', nn.BatchNorm2d(128)) ),\n",
        "            # ( ('cv3', BinarizeConv2d(128,1024, kernel_size=(3, 3), stride = (2, 2), bias=False, padding=(2 ,2))) ),\n",
        "            # ( ('bn3', nn.BatchNorm2d(1024) ) ),\n",
        "            # ( ('ap', nn.AdaptiveAvgPool2d(output_size=1)) ),\n",
        "            ( ('fc1', BinarizeLinearLayer(in_features=28*28, out_features=4096)) ),\n",
        "            ( ('bn1', nn.BatchNorm1d(4096)) ),\n",
        "            ( ('fc2', BinarizeLinearLayer(in_features=4096, out_features=4096)) ),\n",
        "            ( ('bn2', nn.BatchNorm1d(4096)) ),\n",
        "            ( ('fc3', BinarizeLinearLayer(in_features=4096, out_features=n_labels)) ),\n",
        "            ( ('bn3', nn.BatchNorm1d(n_labels)) ),\n",
        "        ]\n",
        "        \n",
        "        self.layers = torch.nn.ModuleDict(OrderedDict(self.layer_list))\n",
        "\n",
        "        for key in self.layers.keys():\n",
        "            if not('bn' in key) and not('ap' in key):\n",
        "                if init == \"gauss\":\n",
        "                    torch.nn.init.normal_(self.layers[key].weight, mean=0, std=width)\n",
        "                if init == \"uniform\":\n",
        "                    torch.nn.init.uniform_(self.layers[key].weight, a= -width/2, b=width/2)\n",
        "    \n",
        "    def save_weight(self):\n",
        "      weights = {}\n",
        "      for name, param in self.named_parameters():\n",
        "        if hasattr(param, 'org'):\n",
        "          if name not in weights.keys():\n",
        "            weights[name]= []\n",
        "          weights[name].append(param.org.cpu().reshape(-1))\n",
        "      return weights\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        self.layers['fc1'].is_input = True\n",
        "        \n",
        "        x = self.layers['fc1'](x)\n",
        "        if x.shape[0] !=1 :\n",
        "            x = self.layers['bn1'](x)\n",
        "        x = SignActivation.apply(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.layers['fc2'](x)\n",
        "        if x.shape[0] !=1 :\n",
        "            x = self.layers['bn2'](x)\n",
        "        x = SignActivation.apply(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.layers['fc3'](x)\n",
        "        if x.shape[0] !=1 :\n",
        "            x = self.layers['bn3'](x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "nHajLE41epOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(mean=(0.0,), std=(1.0,))])\n",
        "\n",
        "mnist_dset_train = torchvision.datasets.MNIST('./mnist_pytorch', train=True, transform=transform, target_transform=None, download=True)\n",
        "mnist_train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=100, shuffle=True, num_workers=1)\n",
        "\n",
        "mnist_dset_test = torchvision.datasets.MNIST('./mnist_pytorch', train=False, transform=transform, target_transform=None, download=True)\n",
        "mnist_test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=100, shuffle=False, num_workers=1)\n"
      ],
      "metadata": {
        "id": "FwVYAbcHe0M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_permuted_loaders():\n",
        "  permut = torch.from_numpy(np.random.permutation(784))\n",
        "      \n",
        "  transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                    torchvision.transforms.Lambda(lambda x: x.view(-1)[permut].view(1, 28, 28) ),\n",
        "                    torchvision.transforms.Normalize(mean=(0.0,), std=(1.0,))\n",
        "                    ])\n",
        "  \n",
        "  dset_train = torchvision.datasets.MNIST('./mnist_pytorch', train=True, transform=transform, target_transform=None, download=True)\n",
        "  train_loader = torch.utils.data.DataLoader(dset_train, batch_size=100, shuffle=True, num_workers=1)\n",
        "\n",
        "  dset_test = torchvision.datasets.MNIST('./mnist_pytorch', train=False, transform=transform, target_transform=None, download=True)\n",
        "  test_loader = torch.utils.data.DataLoader(dset_test, batch_size=1000, shuffle=False, num_workers=1)\n",
        "\n",
        "  return train_loader, test_loader, dset_train"
      ],
      "metadata": {
        "id": "hIApTUygg1Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "permut_train_loader, permut_test_loader, _ = create_permuted_loaders()"
      ],
      "metadata": {
        "id": "dzl9YdD5n9QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fmnist_dset_train = torchvision.datasets.FashionMNIST('./fmnist_pytorch', train=True, transform=transform, target_transform=None, download=True)\n",
        "fashion_mnist_train_loader = torch.utils.data.DataLoader(fmnist_dset_train, batch_size=100, shuffle=True, num_workers=1)\n",
        "\n",
        "fmnist_dset_test = torchvision.datasets.FashionMNIST('./fmnist_pytorch', train=False, transform=transform, target_transform=None, download=True)\n",
        "fashion_mnist_test_loader = torch.utils.data.DataLoader(fmnist_dset_test, batch_size=100, shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "id": "geoyihCLEeNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetProcessing(torch.utils.data.Dataset): \n",
        "    def __init__(self, data, target, transform=None): \n",
        "        self.transform = transform\n",
        "        self.data = data.astype(np.float32)[:,:,None]\n",
        "        self.target = torch.from_numpy(target).long()\n",
        "    def __getitem__(self, index): \n",
        "        if self.transform is not None:\n",
        "            return self.transform(self.data[index]), self.target[index]\n",
        "        else:\n",
        "            return self.data[index], self.target[index]\n",
        "    def __len__(self): \n",
        "        return len(list(self.data))\n",
        "\n",
        "\n",
        "def process_features(X_train, X_test, mode):\n",
        "    if mode==\"cutoff\":\n",
        "        cutoff = 8\n",
        "        threshold_train = np.zeros((np.shape(X_train)[0],1))\n",
        "        threshold_test = np.zeros((np.shape(X_test)[0],1)) \n",
        "        for i in range(np.shape(X_train)[0]):\n",
        "            threshold_train[i,0] = np.unique(X_train[i,:])[-cutoff]\n",
        "        for i in range(np.shape(X_test)[0]):\n",
        "            threshold_test[i,0] = np.unique(X_test[i,:])[-cutoff]\n",
        "        X_train =   (np.sign(X_train  - threshold_train + 1e-6 ) + 1.0)/2\n",
        "        X_test =  (np.sign (X_test  - threshold_test +1e-6 ) + 1.0)/2\n",
        "    elif mode==\"mean_over_examples\":\n",
        "        X_train = ( X_train - X_train.mean(axis = 0, keepdims = True) )/ X_train.var(axis =0, keepdims = True) # ???\n",
        "        X_test = ( X_test - X_test.mean(axis=0, keepdims = True) ) /X_test.var(axis = 0, keepdims = True)\n",
        "    elif mode==\"mean_over_examples_sign\":\n",
        "        X_train =   (np.sign(X_train  - X_train.mean(axis = 0, keepdims = True) ) + 1.0)/2\n",
        "        X_test =  (np.sign (X_test  - X_test.mean(axis = 0, keepdims = True) ) + 1.0)/2\n",
        "    elif mode==\"mean_over_pixels\":\n",
        "        X_train = ( X_train - X_train.mean(axis = 1, keepdims = True) )/ X_train.var(axis =1, keepdims = True)  # Instance norm\n",
        "        X_test = ( X_test - X_test.mean(axis=1, keepdims = True) ) /X_test.var(axis = 1, keepdims = True)\n",
        "    elif mode==\"mean_over_pixels_sign\":\n",
        "        X_train =   (np.sign(X_train  - X_train.mean(axis = 1, keepdims = True) ) + 1.0)/2  \n",
        "        X_test =  (np.sign (X_test  - X_test.mean(axis = 1, keepdims = True) ) + 1.0)/2\n",
        "    elif mode==\"global_mean\":\n",
        "        X_train = ( X_train - X_train.mean(keepdims = True) )/ X_train.var(keepdims = True) # Batch norm\n",
        "        X_test = ( X_test - X_test.mean(keepdims = True) ) /X_test.var(keepdims = True)\n",
        "    elif mode==\"rescale\":\n",
        "        X_train =  (X_train / X_train.max(axis = 1, keepdims = True) )\n",
        "        X_test =  (X_test / X_test.max(axis = 1, keepdims = True) )\n",
        "    return X_train, X_test\n",
        "\n",
        "\n",
        "def relabel(label):\n",
        "    label_map = [5,6,0,1,2,3,4,7,8,9]\n",
        "    return label_map[label]\n",
        "\n",
        "vrelabel = np.vectorize(relabel)\n",
        "\n",
        "\n",
        "def process_cifar10(subset):\n",
        "\n",
        "    cifar_X_train = torch.load('cifar10_features_dataset/train.pt').cpu().numpy()\n",
        "    cifar_Y_train = torch.load('cifar10_features_dataset/train_targets.pt').cpu().numpy() \n",
        "    cifar_X_test = torch.load('cifar10_features_dataset/test.pt').cpu().numpy() \n",
        "    cifar_Y_test = torch.load('cifar10_features_dataset/test_targets.pt').cpu().numpy()\n",
        "\n",
        "    cifar_Y_train = vrelabel(cifar_Y_train)\n",
        "    cifar_Y_test = vrelabel(cifar_Y_test)\n",
        "\n",
        "    if subset=='animals':\n",
        "        partition = np.vectorize(lambda l: l < 5) \n",
        "    elif subset=='vehicles':\n",
        "        partition = np.vectorize(lambda l: l >= 5)  \n",
        "    else:\n",
        "        raise('error unsuported subset')\n",
        " \n",
        "    mode = 'mean_over_pixels'\n",
        "    sub_X_train = cifar_X_train[partition(cifar_Y_train)] \n",
        "    sub_X_test = cifar_X_test[partition(cifar_Y_test)] \n",
        " \n",
        "    sub_X_train, sub_X_test = process_features(sub_X_train, sub_X_test, mode) \n",
        " \n",
        "    sub_Y_train = cifar_Y_train[partition(cifar_Y_train)] \n",
        "    sub_Y_test = cifar_Y_test[partition(cifar_Y_test)] \n",
        " \n",
        "    sub_dset_train = DatasetProcessing(sub_X_train, sub_Y_train) \n",
        "    sub_train_loader = torch.utils.data.DataLoader(sub_dset_train, batch_size=100, shuffle=True, num_workers=4) \n",
        " \n",
        "    sub_dset_test = DatasetProcessing(sub_X_test, sub_Y_test) \n",
        "    sub_test_loader = torch.utils.data.DataLoader(sub_dset_test, batch_size=100, shuffle=False, num_workers=0) \n",
        " \n",
        "    return sub_train_loader, sub_test_loader, sub_dset_train \n"
      ],
      "metadata": {
        "id": "Fr9DD2o-FkQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_dict = {}\n",
        "acc_dict = {}\n",
        "ds = {\n",
        "    '1': {\n",
        "        'train': mnist_train_loader,\n",
        "        'test': mnist_test_loader\n",
        "    },\n",
        "    '2': {\n",
        "        'train': permut_train_loader,\n",
        "        'test': permut_test_loader   \n",
        "    },\n",
        "    '3': {\n",
        "        'train': fashion_mnist_train_loader,\n",
        "        'test': fashion_mnist_test_loader\n",
        "    }\n",
        "}\n",
        "meta = [1.35]\n",
        "epochs = 30\n",
        "model = AudioClassifierBNN().to(DEVICE)"
      ],
      "metadata": {
        "id": "EipvBqbxjcuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dl = []\n",
        "val_dl.append(ds['1']['test'])\n",
        "val_dl.append(ds['3']['test'])"
      ],
      "metadata": {
        "id": "aUXepQzZtFtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for meta in meta: \n",
        "  \n",
        "  model = AudioClassifierBNN().to(DEVICE)\n",
        "  for task in ['1', '3']:\n",
        "    train_dl = ds[task]['train']\n",
        "    loss, acc, test_acc, weights = train(model, train_dl, val_dl, epochs=epochs, optim='meta', meta=meta, weight_decay=1e-08)\n",
        "    loss_dict[task] = loss\n",
        "    acc_dict[task] = test_acc\n",
        "\n",
        "  plt.figure(figsize=(12,8))\n",
        "  plt.plot(acc_dict['1']['0']+acc_dict['3']['0'])\n",
        "  plt.plot(acc_dict['1']['1']+acc_dict['3']['1'])\n",
        "\n",
        "  plt.savefig(f'plot_meta_{meta}.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZaYlZfJunHq1",
        "outputId": "78db21f4-530e-4c80-a3f4-48bbfed896dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   101] loss: 5.662\n",
            "0:00:02.601149\n",
            "[1,   201] loss: 8.748\n",
            "0:00:02.444484\n",
            "[1,   301] loss: 11.437\n",
            "0:00:02.419837\n",
            "[1,   401] loss: 13.611\n",
            "0:00:02.415644\n",
            "[1,   501] loss: 15.707\n",
            "0:00:02.408424\n",
            "Epoch: 0, Loss: 0.29, Accuracy: 0.93\n",
            "Accuracy: 0.95, Loss: 0.14, Total items: 10000\n",
            "Accuracy: 0.06, Loss: 4.79, Total items: 10000\n",
            "[2,   101] loss: 1.663\n",
            "0:00:02.551331\n",
            "[2,   201] loss: 3.218\n",
            "0:00:02.476928\n",
            "[2,   301] loss: 4.658\n",
            "0:00:03.428413\n",
            "[2,   401] loss: 6.184\n",
            "0:00:02.446319\n",
            "[2,   501] loss: 7.655\n",
            "0:00:02.623122\n",
            "Epoch: 1, Loss: 0.15, Accuracy: 0.96\n",
            "Accuracy: 0.96, Loss: 0.09, Total items: 10000\n",
            "Accuracy: 0.10, Loss: 4.42, Total items: 10000\n",
            "[3,   101] loss: 1.109\n",
            "0:00:02.550293\n",
            "[3,   201] loss: 2.311\n",
            "0:00:02.471578\n",
            "[3,   301] loss: 3.466\n",
            "0:00:02.493839\n",
            "[3,   401] loss: 4.679\n",
            "0:00:02.448996\n",
            "[3,   501] loss: 5.912\n",
            "0:00:02.398933\n",
            "Epoch: 2, Loss: 0.12, Accuracy: 0.96\n",
            "Accuracy: 0.96, Loss: 0.08, Total items: 10000\n",
            "Accuracy: 0.09, Loss: 5.19, Total items: 10000\n",
            "[4,   101] loss: 0.914\n",
            "0:00:02.547465\n",
            "[4,   201] loss: 1.846\n",
            "0:00:02.388329\n",
            "[4,   301] loss: 2.907\n",
            "0:00:02.398153\n",
            "[4,   401] loss: 3.886\n",
            "0:00:02.417911\n",
            "[4,   501] loss: 4.878\n",
            "0:00:02.403077\n",
            "Epoch: 3, Loss: 0.10, Accuracy: 0.97\n",
            "Accuracy: 0.96, Loss: 0.06, Total items: 10000\n",
            "Accuracy: 0.08, Loss: 5.46, Total items: 10000\n",
            "[5,   101] loss: 0.883\n",
            "0:00:02.584450\n",
            "[5,   201] loss: 1.696\n",
            "0:00:02.440731\n",
            "[5,   301] loss: 2.462\n",
            "0:00:02.389231\n",
            "[5,   401] loss: 3.281\n",
            "0:00:02.455667\n",
            "[5,   501] loss: 4.185\n",
            "0:00:02.436728\n",
            "Epoch: 4, Loss: 0.08, Accuracy: 0.97\n",
            "Accuracy: 0.97, Loss: 0.05, Total items: 10000\n",
            "Accuracy: 0.07, Loss: 6.21, Total items: 10000\n",
            "[6,   101] loss: 0.638\n",
            "0:00:02.606182\n",
            "[6,   201] loss: 1.344\n",
            "0:00:02.476587\n",
            "[6,   301] loss: 2.124\n",
            "0:00:02.427834\n",
            "[6,   401] loss: 2.852\n",
            "0:00:02.474366\n",
            "[6,   501] loss: 3.588\n",
            "0:00:02.455620\n",
            "Epoch: 5, Loss: 0.07, Accuracy: 0.98\n",
            "Accuracy: 0.97, Loss: 0.07, Total items: 10000\n",
            "Accuracy: 0.09, Loss: 5.74, Total items: 10000\n",
            "[7,   101] loss: 0.599\n",
            "0:00:02.616354\n",
            "[7,   201] loss: 1.168\n",
            "0:00:03.084342\n",
            "[7,   301] loss: 1.837\n",
            "0:00:02.461958\n",
            "[7,   401] loss: 2.489\n",
            "0:00:02.425350\n",
            "[7,   501] loss: 3.188\n",
            "0:00:02.394346\n",
            "Epoch: 6, Loss: 0.06, Accuracy: 0.98\n",
            "Accuracy: 0.97, Loss: 0.03, Total items: 10000\n",
            "Accuracy: 0.08, Loss: 6.52, Total items: 10000\n",
            "[8,   101] loss: 0.454\n",
            "0:00:02.612481\n",
            "[8,   201] loss: 0.995\n",
            "0:00:02.488091\n",
            "[8,   301] loss: 1.548\n",
            "0:00:02.434149\n",
            "[8,   401] loss: 2.119\n",
            "0:00:02.411504\n",
            "[8,   501] loss: 2.611\n",
            "0:00:02.428963\n",
            "Epoch: 7, Loss: 0.05, Accuracy: 0.98\n",
            "Accuracy: 0.97, Loss: 0.08, Total items: 10000\n",
            "Accuracy: 0.08, Loss: 6.14, Total items: 10000\n",
            "[9,   101] loss: 0.381\n",
            "0:00:02.540278\n",
            "[9,   201] loss: 0.780\n",
            "0:00:02.423798\n",
            "[9,   301] loss: 1.213\n",
            "0:00:02.447487\n",
            "[9,   401] loss: 1.686\n",
            "0:00:02.433516\n",
            "[9,   501] loss: 2.240\n",
            "0:00:02.415310\n",
            "Epoch: 8, Loss: 0.05, Accuracy: 0.99\n",
            "Accuracy: 0.97, Loss: 0.06, Total items: 10000\n",
            "Accuracy: 0.08, Loss: 6.59, Total items: 10000\n",
            "[10,   101] loss: 0.341\n",
            "0:00:02.564737\n",
            "[10,   201] loss: 0.667\n",
            "0:00:02.433443\n",
            "[10,   301] loss: 1.020\n",
            "0:00:02.461617\n",
            "[10,   401] loss: 1.400\n",
            "0:00:02.455649\n",
            "[10,   501] loss: 1.918\n",
            "0:00:02.474782\n",
            "Epoch: 9, Loss: 0.04, Accuracy: 0.99\n",
            "Accuracy: 0.97, Loss: 0.03, Total items: 10000\n",
            "Accuracy: 0.09, Loss: 6.77, Total items: 10000\n",
            "[11,   101] loss: 0.320\n",
            "0:00:02.540992\n",
            "[11,   201] loss: 0.610\n",
            "0:00:02.427544\n",
            "[11,   301] loss: 0.926\n",
            "0:00:02.549652\n",
            "[11,   401] loss: 1.283\n",
            "0:00:02.484454\n",
            "[11,   501] loss: 1.642\n",
            "0:00:02.459378\n",
            "Epoch: 10, Loss: 0.03, Accuracy: 0.99\n",
            "Accuracy: 0.97, Loss: 0.05, Total items: 10000\n",
            "Accuracy: 0.09, Loss: 7.23, Total items: 10000\n",
            "[12,   101] loss: 0.271\n",
            "0:00:02.559861\n",
            "[12,   201] loss: 0.516\n",
            "0:00:02.413080\n",
            "[12,   301] loss: 0.736\n",
            "0:00:02.419160\n",
            "[12,   401] loss: 1.035\n",
            "0:00:02.402092\n",
            "[12,   501] loss: 1.404\n",
            "0:00:02.430871\n",
            "Epoch: 11, Loss: 0.03, Accuracy: 0.99\n",
            "Accuracy: 0.97, Loss: 0.01, Total items: 10000\n",
            "Accuracy: 0.07, Loss: 7.67, Total items: 10000\n",
            "[13,   101] loss: 0.217\n",
            "0:00:02.571063\n",
            "[13,   201] loss: 0.453\n",
            "0:00:02.437443\n",
            "[13,   301] loss: 0.707\n",
            "0:00:02.433933\n",
            "[13,   401] loss: 1.056\n",
            "0:00:02.399684\n",
            "[13,   501] loss: 1.323\n",
            "0:00:02.408314\n",
            "Epoch: 12, Loss: 0.03, Accuracy: 0.99\n",
            "Accuracy: 0.97, Loss: 0.05, Total items: 10000\n",
            "Accuracy: 0.05, Loss: 7.88, Total items: 10000\n",
            "[14,   101] loss: 0.193\n",
            "0:00:02.563405\n",
            "[14,   201] loss: 0.421\n",
            "0:00:02.425232\n",
            "[14,   301] loss: 0.619\n",
            "0:00:02.379380\n",
            "[14,   401] loss: 0.895\n",
            "0:00:02.374375\n",
            "[14,   501] loss: 1.141\n",
            "0:00:02.393851\n",
            "Epoch: 13, Loss: 0.02, Accuracy: 0.99\n",
            "Accuracy: 0.97, Loss: 0.07, Total items: 10000\n",
            "Accuracy: 0.07, Loss: 8.22, Total items: 10000\n",
            "[15,   101] loss: 0.213\n",
            "0:00:02.528289\n",
            "[15,   201] loss: 0.395\n",
            "0:00:02.478246\n",
            "[15,   301] loss: 0.596\n",
            "0:00:02.475060\n",
            "[15,   401] loss: 0.775\n",
            "0:00:02.425483\n",
            "[15,   501] loss: 1.017\n",
            "0:00:02.402659\n",
            "Epoch: 14, Loss: 0.02, Accuracy: 0.99\n",
            "Accuracy: 0.97, Loss: 0.01, Total items: 10000\n",
            "Accuracy: 0.08, Loss: 7.72, Total items: 10000\n",
            "[16,   101] loss: 0.169\n",
            "0:00:02.546672\n",
            "[16,   201] loss: 0.340\n",
            "0:00:02.456444\n",
            "[16,   301] loss: 0.556\n",
            "0:00:02.438641\n",
            "[16,   401] loss: 0.805\n",
            "0:00:02.408132\n",
            "[16,   501] loss: 1.000\n",
            "0:00:02.431153\n",
            "Epoch: 15, Loss: 0.02, Accuracy: 0.99\n",
            "Accuracy: 0.97, Loss: 0.03, Total items: 10000\n",
            "Accuracy: 0.07, Loss: 8.23, Total items: 10000\n",
            "[17,   101] loss: 0.121\n",
            "0:00:02.533401\n",
            "[17,   201] loss: 0.310\n",
            "0:00:02.418679\n",
            "[17,   301] loss: 0.471\n",
            "0:00:02.429802\n",
            "[17,   401] loss: 0.624\n",
            "0:00:02.389177\n",
            "[17,   501] loss: 0.863\n",
            "0:00:02.406491\n",
            "Epoch: 16, Loss: 0.02, Accuracy: 0.99\n",
            "Accuracy: 0.97, Loss: 0.04, Total items: 10000\n",
            "Accuracy: 0.06, Loss: 8.20, Total items: 10000\n",
            "[18,   101] loss: 0.166\n",
            "0:00:02.554673\n",
            "[18,   201] loss: 0.314\n",
            "0:00:02.408249\n",
            "[18,   301] loss: 0.477\n",
            "0:00:02.437648\n",
            "[18,   401] loss: 0.616\n",
            "0:00:02.440045\n",
            "[18,   501] loss: 0.807\n",
            "0:00:02.411560\n",
            "Epoch: 17, Loss: 0.02, Accuracy: 0.99\n",
            "Accuracy: 0.98, Loss: 0.03, Total items: 10000\n",
            "Accuracy: 0.06, Loss: 8.91, Total items: 10000\n",
            "[19,   101] loss: 0.103\n",
            "0:00:02.514377\n",
            "[19,   201] loss: 0.223\n",
            "0:00:02.384557\n",
            "[19,   301] loss: 0.372\n",
            "0:00:02.448972\n",
            "[19,   401] loss: 0.479\n",
            "0:00:02.467139\n",
            "[19,   501] loss: 0.611\n",
            "0:00:02.495399\n",
            "Epoch: 18, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.98, Loss: 0.04, Total items: 10000\n",
            "Accuracy: 0.06, Loss: 8.63, Total items: 10000\n",
            "[20,   101] loss: 0.100\n",
            "0:00:02.562358\n",
            "[20,   201] loss: 0.192\n",
            "0:00:02.447589\n",
            "[20,   301] loss: 0.317\n",
            "0:00:02.458955\n",
            "[20,   401] loss: 0.400\n",
            "0:00:02.457337\n",
            "[20,   501] loss: 0.518\n",
            "0:00:02.452475\n",
            "Epoch: 19, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.97, Loss: 0.06, Total items: 10000\n",
            "Accuracy: 0.06, Loss: 8.77, Total items: 10000\n",
            "[21,   101] loss: 0.133\n",
            "0:00:02.603678\n",
            "[21,   201] loss: 0.267\n",
            "0:00:02.523977\n",
            "[21,   301] loss: 0.413\n",
            "0:00:02.508359\n",
            "[21,   401] loss: 0.541\n",
            "0:00:02.509579\n",
            "[21,   501] loss: 0.678\n",
            "0:00:02.476120\n",
            "Epoch: 20, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.97, Loss: 0.01, Total items: 10000\n",
            "Accuracy: 0.09, Loss: 8.76, Total items: 10000\n",
            "[22,   101] loss: 0.127\n",
            "0:00:02.538407\n",
            "[22,   201] loss: 0.268\n",
            "0:00:02.433668\n",
            "[22,   301] loss: 0.411\n",
            "0:00:02.394408\n",
            "[22,   401] loss: 0.569\n",
            "0:00:02.384758\n",
            "[22,   501] loss: 0.700\n",
            "0:00:02.428233\n",
            "Epoch: 21, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.97, Loss: 0.03, Total items: 10000\n",
            "Accuracy: 0.08, Loss: 9.35, Total items: 10000\n",
            "[23,   101] loss: 0.095\n",
            "0:00:02.555462\n",
            "[23,   201] loss: 0.165\n",
            "0:00:02.391184\n",
            "[23,   301] loss: 0.220\n",
            "0:00:02.397490\n",
            "[23,   401] loss: 0.297\n",
            "0:00:02.401084\n",
            "[23,   501] loss: 0.401\n",
            "0:00:02.385478\n",
            "Epoch: 22, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.98, Loss: 0.01, Total items: 10000\n",
            "Accuracy: 0.06, Loss: 8.87, Total items: 10000\n",
            "[24,   101] loss: 0.139\n",
            "0:00:02.537440\n",
            "[24,   201] loss: 0.284\n",
            "0:00:02.411808\n",
            "[24,   301] loss: 0.383\n",
            "0:00:02.432211\n",
            "[24,   401] loss: 0.491\n",
            "0:00:02.471874\n",
            "[24,   501] loss: 0.644\n",
            "0:00:02.412334\n",
            "Epoch: 23, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.97, Loss: 0.01, Total items: 10000\n",
            "Accuracy: 0.05, Loss: 9.98, Total items: 10000\n",
            "[25,   101] loss: 0.083\n",
            "0:00:02.532285\n",
            "[25,   201] loss: 0.165\n",
            "0:00:02.395177\n",
            "[25,   301] loss: 0.266\n",
            "0:00:02.427096\n",
            "[25,   401] loss: 0.367\n",
            "0:00:02.460285\n",
            "[25,   501] loss: 0.457\n",
            "0:00:02.419312\n",
            "Epoch: 24, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.98, Loss: 0.01, Total items: 10000\n",
            "Accuracy: 0.08, Loss: 9.40, Total items: 10000\n",
            "[26,   101] loss: 0.081\n",
            "0:00:02.535175\n",
            "[26,   201] loss: 0.170\n",
            "0:00:02.425358\n",
            "[26,   301] loss: 0.258\n",
            "0:00:02.448362\n",
            "[26,   401] loss: 0.339\n",
            "0:00:02.396621\n",
            "[26,   501] loss: 0.447\n",
            "0:00:02.405354\n",
            "Epoch: 25, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.97, Loss: 0.03, Total items: 10000\n",
            "Accuracy: 0.07, Loss: 10.33, Total items: 10000\n",
            "[27,   101] loss: 0.071\n",
            "0:00:02.525207\n",
            "[27,   201] loss: 0.152\n",
            "0:00:02.396639\n",
            "[27,   301] loss: 0.234\n",
            "0:00:02.383627\n",
            "[27,   401] loss: 0.375\n",
            "0:00:02.398724\n",
            "[27,   501] loss: 0.477\n",
            "0:00:02.436926\n",
            "Epoch: 26, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.97, Loss: 0.00, Total items: 10000\n",
            "Accuracy: 0.06, Loss: 10.60, Total items: 10000\n",
            "[28,   101] loss: 0.072\n",
            "0:00:02.543425\n",
            "[28,   201] loss: 0.165\n",
            "0:00:02.456410\n",
            "[28,   301] loss: 0.248\n",
            "0:00:02.432620\n",
            "[28,   401] loss: 0.356\n",
            "0:00:02.391874\n",
            "[28,   501] loss: 0.463\n",
            "0:00:02.423253\n",
            "Epoch: 27, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.97, Loss: 0.02, Total items: 10000\n",
            "Accuracy: 0.06, Loss: 10.36, Total items: 10000\n",
            "[29,   101] loss: 0.090\n",
            "0:00:02.549944\n",
            "[29,   201] loss: 0.172\n",
            "0:00:02.417253\n",
            "[29,   301] loss: 0.250\n",
            "0:00:02.427177\n",
            "[29,   401] loss: 0.323\n",
            "0:00:02.454937\n",
            "[29,   501] loss: 0.389\n",
            "0:00:02.443556\n",
            "Epoch: 28, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.97, Loss: 0.05, Total items: 10000\n",
            "Accuracy: 0.06, Loss: 9.95, Total items: 10000\n",
            "[30,   101] loss: 0.071\n",
            "0:00:02.540211\n",
            "[30,   201] loss: 0.135\n",
            "0:00:02.391822\n",
            "[30,   301] loss: 0.210\n",
            "0:00:02.412762\n",
            "[30,   401] loss: 0.266\n",
            "0:00:02.396066\n",
            "[30,   501] loss: 0.344\n",
            "0:00:02.396672\n",
            "Epoch: 29, Loss: 0.01, Accuracy: 1.00\n",
            "Accuracy: 0.97, Loss: 0.09, Total items: 10000\n",
            "Accuracy: 0.06, Loss: 9.91, Total items: 10000\n",
            "[1,   101] loss: 9.089\n",
            "0:00:02.559489\n",
            "[1,   201] loss: 13.751\n",
            "0:00:02.460704\n",
            "[1,   301] loss: 18.047\n",
            "0:00:02.443795\n",
            "[1,   401] loss: 22.035\n",
            "0:00:02.378821\n",
            "[1,   501] loss: 26.087\n",
            "0:00:02.423266\n",
            "Epoch: 0, Loss: 0.50, Accuracy: 0.84\n",
            "Accuracy: 0.46, Loss: 3.63, Total items: 10000\n",
            "Accuracy: 0.85, Loss: 0.48, Total items: 10000\n",
            "[2,   101] loss: 3.559\n",
            "0:00:02.553769\n",
            "[2,   201] loss: 6.996\n",
            "0:00:02.428359\n",
            "[2,   301] loss: 10.411\n",
            "0:00:02.428179\n",
            "[2,   401] loss: 13.908\n",
            "0:00:02.447554\n",
            "[2,   501] loss: 17.341\n",
            "0:00:02.442594\n",
            "Epoch: 1, Loss: 0.34, Accuracy: 0.88\n",
            "Accuracy: 0.47, Loss: 3.65, Total items: 10000\n",
            "Accuracy: 0.85, Loss: 0.44, Total items: 10000\n",
            "[3,   101] loss: 2.926\n",
            "0:00:02.545131\n",
            "[3,   201] loss: 6.101\n",
            "0:00:02.478976\n",
            "[3,   301] loss: 9.165\n",
            "0:00:02.422232\n",
            "[3,   401] loss: 12.209\n",
            "0:00:02.422440\n",
            "[3,   501] loss: 15.551\n",
            "0:00:02.402484\n",
            "Epoch: 2, Loss: 0.31, Accuracy: 0.89\n",
            "Accuracy: 0.47, Loss: 4.35, Total items: 10000\n",
            "Accuracy: 0.86, Loss: 0.38, Total items: 10000\n",
            "[4,   101] loss: 2.555\n",
            "0:00:02.578573\n",
            "[4,   201] loss: 5.435\n",
            "0:00:02.481370\n",
            "[4,   301] loss: 8.261\n",
            "0:00:02.503080\n",
            "[4,   401] loss: 11.110\n",
            "0:00:02.433123\n",
            "[4,   501] loss: 13.940\n",
            "0:00:02.459451\n",
            "Epoch: 3, Loss: 0.28, Accuracy: 0.90\n",
            "Accuracy: 0.50, Loss: 3.87, Total items: 10000\n",
            "Accuracy: 0.87, Loss: 0.39, Total items: 10000\n",
            "[5,   101] loss: 2.493\n",
            "0:00:02.558755\n",
            "[5,   201] loss: 5.000\n",
            "0:00:02.386434\n",
            "[5,   301] loss: 7.669\n",
            "0:00:02.392525\n",
            "[5,   401] loss: 10.312\n",
            "0:00:02.409393\n",
            "[5,   501] loss: 12.990\n",
            "0:00:02.408239\n",
            "Epoch: 4, Loss: 0.26, Accuracy: 0.91\n",
            "Accuracy: 0.44, Loss: 5.00, Total items: 10000\n",
            "Accuracy: 0.87, Loss: 0.33, Total items: 10000\n",
            "[6,   101] loss: 2.249\n",
            "0:00:02.602053\n",
            "[6,   201] loss: 4.611\n",
            "0:00:02.410504\n",
            "[6,   301] loss: 6.912\n",
            "0:00:02.388359\n",
            "[6,   401] loss: 9.311\n",
            "0:00:02.400259\n",
            "[6,   501] loss: 11.862\n",
            "0:00:02.409574\n",
            "Epoch: 5, Loss: 0.24, Accuracy: 0.91\n",
            "Accuracy: 0.51, Loss: 3.57, Total items: 10000\n",
            "Accuracy: 0.87, Loss: 0.38, Total items: 10000\n",
            "[7,   101] loss: 2.113\n",
            "0:00:02.540559\n",
            "[7,   201] loss: 4.289\n",
            "0:00:02.416203\n",
            "[7,   301] loss: 6.586\n",
            "0:00:02.388636\n",
            "[7,   401] loss: 8.752\n",
            "0:00:02.495930\n",
            "[7,   501] loss: 10.979\n",
            "0:00:02.447309\n",
            "Epoch: 6, Loss: 0.22, Accuracy: 0.92\n",
            "Accuracy: 0.49, Loss: 3.67, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.33, Total items: 10000\n",
            "[8,   101] loss: 1.889\n",
            "0:00:02.561706\n",
            "[8,   201] loss: 3.866\n",
            "0:00:02.453376\n",
            "[8,   301] loss: 5.791\n",
            "0:00:02.455464\n",
            "[8,   401] loss: 7.774\n",
            "0:00:02.434822\n",
            "[8,   501] loss: 9.752\n",
            "0:00:02.439427\n",
            "Epoch: 7, Loss: 0.20, Accuracy: 0.93\n",
            "Accuracy: 0.50, Loss: 3.56, Total items: 10000\n",
            "Accuracy: 0.87, Loss: 0.39, Total items: 10000\n",
            "[9,   101] loss: 1.766\n",
            "0:00:02.522340\n",
            "[9,   201] loss: 3.616\n",
            "0:00:02.413155\n",
            "[9,   301] loss: 5.442\n",
            "0:00:02.456946\n",
            "[9,   401] loss: 7.257\n",
            "0:00:02.413703\n",
            "[9,   501] loss: 9.137\n",
            "0:00:02.397933\n",
            "Epoch: 8, Loss: 0.18, Accuracy: 0.93\n",
            "Accuracy: 0.48, Loss: 3.61, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.41, Total items: 10000\n",
            "[10,   101] loss: 1.588\n",
            "0:00:02.534906\n",
            "[10,   201] loss: 3.361\n",
            "0:00:02.422035\n",
            "[10,   301] loss: 5.064\n",
            "0:00:02.405675\n",
            "[10,   401] loss: 6.805\n",
            "0:00:02.439593\n",
            "[10,   501] loss: 8.547\n",
            "0:00:02.428091\n",
            "Epoch: 9, Loss: 0.17, Accuracy: 0.94\n",
            "Accuracy: 0.54, Loss: 3.24, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.45, Total items: 10000\n",
            "[11,   101] loss: 1.503\n",
            "0:00:02.558633\n",
            "[11,   201] loss: 3.055\n",
            "0:00:02.422406\n",
            "[11,   301] loss: 4.729\n",
            "0:00:02.380228\n",
            "[11,   401] loss: 6.338\n",
            "0:00:02.402160\n",
            "[11,   501] loss: 7.955\n",
            "0:00:02.416539\n",
            "Epoch: 10, Loss: 0.16, Accuracy: 0.94\n",
            "Accuracy: 0.53, Loss: 3.56, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.39, Total items: 10000\n",
            "[12,   101] loss: 1.296\n",
            "0:00:02.579716\n",
            "[12,   201] loss: 2.771\n",
            "0:00:02.469588\n",
            "[12,   301] loss: 4.211\n",
            "0:00:02.431048\n",
            "[12,   401] loss: 5.625\n",
            "0:00:02.451691\n",
            "[12,   501] loss: 7.099\n",
            "0:00:02.425187\n",
            "Epoch: 11, Loss: 0.14, Accuracy: 0.95\n",
            "Accuracy: 0.55, Loss: 3.43, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.45, Total items: 10000\n",
            "[13,   101] loss: 1.205\n",
            "0:00:02.528993\n",
            "[13,   201] loss: 2.510\n",
            "0:00:02.412781\n",
            "[13,   301] loss: 3.855\n",
            "0:00:02.437549\n",
            "[13,   401] loss: 5.226\n",
            "0:00:02.416273\n",
            "[13,   501] loss: 6.664\n",
            "0:00:02.403564\n",
            "Epoch: 12, Loss: 0.13, Accuracy: 0.95\n",
            "Accuracy: 0.58, Loss: 2.56, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.42, Total items: 10000\n",
            "[14,   101] loss: 1.183\n",
            "0:00:02.519627\n",
            "[14,   201] loss: 2.518\n",
            "0:00:02.440111\n",
            "[14,   301] loss: 3.762\n",
            "0:00:02.424945\n",
            "[14,   401] loss: 5.145\n",
            "0:00:02.453059\n",
            "[14,   501] loss: 6.448\n",
            "0:00:02.397688\n",
            "Epoch: 13, Loss: 0.13, Accuracy: 0.95\n",
            "Accuracy: 0.58, Loss: 3.42, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.39, Total items: 10000\n",
            "[15,   101] loss: 1.135\n",
            "0:00:02.552624\n",
            "[15,   201] loss: 2.218\n",
            "0:00:02.423910\n",
            "[15,   301] loss: 3.418\n",
            "0:00:02.484018\n",
            "[15,   401] loss: 4.604\n",
            "0:00:02.477595\n",
            "[15,   501] loss: 5.887\n",
            "0:00:02.468936\n",
            "Epoch: 14, Loss: 0.12, Accuracy: 0.96\n",
            "Accuracy: 0.58, Loss: 3.35, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.39, Total items: 10000\n",
            "[16,   101] loss: 0.981\n",
            "0:00:02.576805\n",
            "[16,   201] loss: 2.089\n",
            "0:00:02.427333\n",
            "[16,   301] loss: 3.173\n",
            "0:00:02.452331\n",
            "[16,   401] loss: 4.247\n",
            "0:00:02.400786\n",
            "[16,   501] loss: 5.422\n",
            "0:00:02.409487\n",
            "Epoch: 15, Loss: 0.11, Accuracy: 0.96\n",
            "Accuracy: 0.58, Loss: 2.71, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.46, Total items: 10000\n",
            "[17,   101] loss: 0.918\n",
            "0:00:02.597383\n",
            "[17,   201] loss: 1.886\n",
            "0:00:02.427600\n",
            "[17,   301] loss: 2.884\n",
            "0:00:02.452512\n",
            "[17,   401] loss: 3.965\n",
            "0:00:02.419136\n",
            "[17,   501] loss: 4.972\n",
            "0:00:02.480143\n",
            "Epoch: 16, Loss: 0.10, Accuracy: 0.96\n",
            "Accuracy: 0.56, Loss: 3.34, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.43, Total items: 10000\n",
            "[18,   101] loss: 0.891\n",
            "0:00:02.539702\n",
            "[18,   201] loss: 1.795\n",
            "0:00:02.412595\n",
            "[18,   301] loss: 2.780\n",
            "0:00:02.390005\n",
            "[18,   401] loss: 3.759\n",
            "0:00:02.389586\n",
            "[18,   501] loss: 4.832\n",
            "0:00:02.457210\n",
            "Epoch: 17, Loss: 0.10, Accuracy: 0.96\n",
            "Accuracy: 0.56, Loss: 3.10, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.54, Total items: 10000\n",
            "[19,   101] loss: 0.851\n",
            "0:00:02.534326\n",
            "[19,   201] loss: 1.760\n",
            "0:00:02.447103\n",
            "[19,   301] loss: 2.734\n",
            "0:00:02.486477\n",
            "[19,   401] loss: 3.717\n",
            "0:00:02.395982\n",
            "[19,   501] loss: 4.621\n",
            "0:00:02.440353\n",
            "Epoch: 18, Loss: 0.09, Accuracy: 0.97\n",
            "Accuracy: 0.61, Loss: 2.53, Total items: 10000\n",
            "Accuracy: 0.89, Loss: 0.55, Total items: 10000\n",
            "[20,   101] loss: 0.852\n",
            "0:00:02.572033\n",
            "[20,   201] loss: 1.787\n",
            "0:00:02.417094\n",
            "[20,   301] loss: 2.695\n",
            "0:00:02.421099\n",
            "[20,   401] loss: 3.675\n",
            "0:00:02.410984\n",
            "[20,   501] loss: 4.609\n",
            "0:00:02.431102\n",
            "Epoch: 19, Loss: 0.09, Accuracy: 0.97\n",
            "Accuracy: 0.63, Loss: 2.29, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.45, Total items: 10000\n",
            "[21,   101] loss: 0.775\n",
            "0:00:02.568278\n",
            "[21,   201] loss: 1.581\n",
            "0:00:02.439135\n",
            "[21,   301] loss: 2.453\n",
            "0:00:02.461775\n",
            "[21,   401] loss: 3.298\n",
            "0:00:02.482597\n",
            "[21,   501] loss: 4.268\n",
            "0:00:02.490133\n",
            "Epoch: 20, Loss: 0.09, Accuracy: 0.97\n",
            "Accuracy: 0.57, Loss: 3.57, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.33, Total items: 10000\n",
            "[22,   101] loss: 0.749\n",
            "0:00:02.552116\n",
            "[22,   201] loss: 1.503\n",
            "0:00:02.468733\n",
            "[22,   301] loss: 2.339\n",
            "0:00:02.460183\n",
            "[22,   401] loss: 3.277\n",
            "0:00:02.404778\n",
            "[22,   501] loss: 4.191\n",
            "0:00:02.469750\n",
            "Epoch: 21, Loss: 0.08, Accuracy: 0.97\n",
            "Accuracy: 0.55, Loss: 2.98, Total items: 10000\n",
            "Accuracy: 0.89, Loss: 0.42, Total items: 10000\n",
            "[23,   101] loss: 0.692\n",
            "0:00:02.533776\n",
            "[23,   201] loss: 1.473\n",
            "0:00:02.414857\n",
            "[23,   301] loss: 2.297\n",
            "0:00:02.426312\n",
            "[23,   401] loss: 3.153\n",
            "0:00:02.441946\n",
            "[23,   501] loss: 4.000\n",
            "0:00:02.420754\n",
            "Epoch: 22, Loss: 0.08, Accuracy: 0.97\n",
            "Accuracy: 0.61, Loss: 2.74, Total items: 10000\n",
            "Accuracy: 0.89, Loss: 0.58, Total items: 10000\n",
            "[24,   101] loss: 0.735\n",
            "0:00:02.544130\n",
            "[24,   201] loss: 1.558\n",
            "0:00:02.463171\n",
            "[24,   301] loss: 2.376\n",
            "0:00:02.439373\n",
            "[24,   401] loss: 3.175\n",
            "0:00:02.410479\n",
            "[24,   501] loss: 4.008\n",
            "0:00:02.445846\n",
            "Epoch: 23, Loss: 0.08, Accuracy: 0.97\n",
            "Accuracy: 0.51, Loss: 3.92, Total items: 10000\n",
            "Accuracy: 0.89, Loss: 0.33, Total items: 10000\n",
            "[25,   101] loss: 0.721\n",
            "0:00:02.582930\n",
            "[25,   201] loss: 1.503\n",
            "0:00:02.433191\n",
            "[25,   301] loss: 2.186\n",
            "0:00:02.392042\n",
            "[25,   401] loss: 2.947\n",
            "0:00:02.531180\n",
            "[25,   501] loss: 3.677\n",
            "0:00:02.451378\n",
            "Epoch: 24, Loss: 0.07, Accuracy: 0.97\n",
            "Accuracy: 0.65, Loss: 2.31, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.41, Total items: 10000\n",
            "[26,   101] loss: 0.762\n",
            "0:00:02.563304\n",
            "[26,   201] loss: 1.548\n",
            "0:00:02.419439\n",
            "[26,   301] loss: 2.285\n",
            "0:00:02.451384\n",
            "[26,   401] loss: 3.066\n",
            "0:00:02.378725\n",
            "[26,   501] loss: 3.840\n",
            "0:00:02.429499\n",
            "Epoch: 25, Loss: 0.08, Accuracy: 0.97\n",
            "Accuracy: 0.54, Loss: 3.42, Total items: 10000\n",
            "Accuracy: 0.89, Loss: 0.42, Total items: 10000\n",
            "[27,   101] loss: 0.651\n",
            "0:00:02.531559\n",
            "[27,   201] loss: 1.347\n",
            "0:00:02.413084\n",
            "[27,   301] loss: 2.154\n",
            "0:00:02.425082\n",
            "[27,   401] loss: 2.916\n",
            "0:00:02.413567\n",
            "[27,   501] loss: 3.654\n",
            "0:00:02.392412\n",
            "Epoch: 26, Loss: 0.07, Accuracy: 0.97\n",
            "Accuracy: 0.56, Loss: 3.31, Total items: 10000\n",
            "Accuracy: 0.89, Loss: 0.54, Total items: 10000\n",
            "[28,   101] loss: 0.651\n",
            "0:00:02.558043\n",
            "[28,   201] loss: 1.320\n",
            "0:00:02.410954\n",
            "[28,   301] loss: 2.117\n",
            "0:00:02.428263\n",
            "[28,   401] loss: 2.745\n",
            "0:00:02.387200\n",
            "[28,   501] loss: 3.506\n",
            "0:00:02.404896\n",
            "Epoch: 27, Loss: 0.07, Accuracy: 0.98\n",
            "Accuracy: 0.40, Loss: 4.68, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.51, Total items: 10000\n",
            "[29,   101] loss: 0.754\n",
            "0:00:02.532269\n",
            "[29,   201] loss: 1.499\n",
            "0:00:02.407267\n",
            "[29,   301] loss: 2.170\n",
            "0:00:02.413602\n",
            "[29,   401] loss: 2.842\n",
            "0:00:02.404500\n",
            "[29,   501] loss: 3.603\n",
            "0:00:02.401470\n",
            "Epoch: 28, Loss: 0.07, Accuracy: 0.97\n",
            "Accuracy: 0.56, Loss: 3.77, Total items: 10000\n",
            "Accuracy: 0.89, Loss: 0.49, Total items: 10000\n",
            "[30,   101] loss: 0.678\n",
            "0:00:02.541838\n",
            "[30,   201] loss: 1.406\n",
            "0:00:02.440665\n",
            "[30,   301] loss: 2.172\n",
            "0:00:02.431088\n",
            "[30,   401] loss: 2.871\n",
            "0:00:02.409035\n",
            "[30,   501] loss: 3.592\n",
            "0:00:02.400566\n",
            "Epoch: 29, Loss: 0.07, Accuracy: 0.97\n",
            "Accuracy: 0.52, Loss: 4.00, Total items: 10000\n",
            "Accuracy: 0.88, Loss: 0.61, Total items: 10000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(acc_dict['1']['0']+acc_dict['3']['0'])\n",
        "plt.plot(acc_dict['1']['1']+acc_dict['3']['1'])\n",
        "plt.show()\n",
        "plt.savefig(f'plot_meta_{meta}.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "nUurbexcAcvo",
        "outputId": "6b5bc94b-7b54-46b1-fd95-db75131e28d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp plot_* drive/MyDrive"
      ],
      "metadata": {
        "id": "Iw0yI2QjA5RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git init ."
      ],
      "metadata": {
        "id": "_NRcl2P8CB8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d209edb-b26f-4ef8-f650-8a039052e6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Laborieux-Axel/SynapticMetaplasticityBNN.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8_IIEmy3Ic1",
        "outputId": "7b0309ec-6a68-461a-bee4-44c8954a9699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SynapticMetaplasticityBNN'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/99)\u001b[K\rremote: Counting objects:   2% (2/99)\u001b[K\rremote: Counting objects:   3% (3/99)\u001b[K\rremote: Counting objects:   4% (4/99)\u001b[K\rremote: Counting objects:   5% (5/99)\u001b[K\rremote: Counting objects:   6% (6/99)\u001b[K\rremote: Counting objects:   7% (7/99)\u001b[K\rremote: Counting objects:   8% (8/99)\u001b[K\rremote: Counting objects:   9% (9/99)\u001b[K\rremote: Counting objects:  10% (10/99)\u001b[K\rremote: Counting objects:  11% (11/99)\u001b[K\rremote: Counting objects:  12% (12/99)\u001b[K\rremote: Counting objects:  13% (13/99)\u001b[K\rremote: Counting objects:  14% (14/99)\u001b[K\rremote: Counting objects:  15% (15/99)\u001b[K\rremote: Counting objects:  16% (16/99)\u001b[K\rremote: Counting objects:  17% (17/99)\u001b[K\rremote: Counting objects:  18% (18/99)\u001b[K\rremote: Counting objects:  19% (19/99)\u001b[K\rremote: Counting objects:  20% (20/99)\u001b[K\rremote: Counting objects:  21% (21/99)\u001b[K\rremote: Counting objects:  22% (22/99)\u001b[K\rremote: Counting objects:  23% (23/99)\u001b[K\rremote: Counting objects:  24% (24/99)\u001b[K\rremote: Counting objects:  25% (25/99)\u001b[K\rremote: Counting objects:  26% (26/99)\u001b[K\rremote: Counting objects:  27% (27/99)\u001b[K\rremote: Counting objects:  28% (28/99)\u001b[K\rremote: Counting objects:  29% (29/99)\u001b[K\rremote: Counting objects:  30% (30/99)\u001b[K\rremote: Counting objects:  31% (31/99)\u001b[K\rremote: Counting objects:  32% (32/99)\u001b[K\rremote: Counting objects:  33% (33/99)\u001b[K\rremote: Counting objects:  34% (34/99)\u001b[K\rremote: Counting objects:  35% (35/99)\u001b[K\rremote: Counting objects:  36% (36/99)\u001b[K\rremote: Counting objects:  37% (37/99)\u001b[K\rremote: Counting objects:  38% (38/99)\u001b[K\rremote: Counting objects:  39% (39/99)\u001b[K\rremote: Counting objects:  40% (40/99)\u001b[K\rremote: Counting objects:  41% (41/99)\u001b[K\rremote: Counting objects:  42% (42/99)\u001b[K\rremote: Counting objects:  43% (43/99)\u001b[K\rremote: Counting objects:  44% (44/99)\u001b[K\rremote: Counting objects:  45% (45/99)\u001b[K\rremote: Counting objects:  46% (46/99)\u001b[K\rremote: Counting objects:  47% (47/99)\u001b[K\rremote: Counting objects:  48% (48/99)\u001b[K\rremote: Counting objects:  49% (49/99)\u001b[K\rremote: Counting objects:  50% (50/99)\u001b[K\rremote: Counting objects:  51% (51/99)\u001b[K\rremote: Counting objects:  52% (52/99)\u001b[K\rremote: Counting objects:  53% (53/99)\u001b[K\rremote: Counting objects:  54% (54/99)\u001b[K\rremote: Counting objects:  55% (55/99)\u001b[K\rremote: Counting objects:  56% (56/99)\u001b[K\rremote: Counting objects:  57% (57/99)\u001b[K\rremote: Counting objects:  58% (58/99)\u001b[K\rremote: Counting objects:  59% (59/99)\u001b[K\rremote: Counting objects:  60% (60/99)\u001b[K\rremote: Counting objects:  61% (61/99)\u001b[K\rremote: Counting objects:  62% (62/99)\u001b[K\rremote: Counting objects:  63% (63/99)\u001b[K\rremote: Counting objects:  64% (64/99)\u001b[K\rremote: Counting objects:  65% (65/99)\u001b[K\rremote: Counting objects:  66% (66/99)\u001b[K\rremote: Counting objects:  67% (67/99)\u001b[K\rremote: Counting objects:  68% (68/99)\u001b[K\rremote: Counting objects:  69% (69/99)\u001b[K\rremote: Counting objects:  70% (70/99)\u001b[K\rremote: Counting objects:  71% (71/99)\u001b[K\rremote: Counting objects:  72% (72/99)\u001b[K\rremote: Counting objects:  73% (73/99)\u001b[K\rremote: Counting objects:  74% (74/99)\u001b[K\rremote: Counting objects:  75% (75/99)\u001b[K\rremote: Counting objects:  76% (76/99)\u001b[K\rremote: Counting objects:  77% (77/99)\u001b[K\rremote: Counting objects:  78% (78/99)\u001b[K\rremote: Counting objects:  79% (79/99)\u001b[K\rremote: Counting objects:  80% (80/99)\u001b[K\rremote: Counting objects:  81% (81/99)\u001b[K\rremote: Counting objects:  82% (82/99)\u001b[K\rremote: Counting objects:  83% (83/99)\u001b[K\rremote: Counting objects:  84% (84/99)\u001b[K\rremote: Counting objects:  85% (85/99)\u001b[K\rremote: Counting objects:  86% (86/99)\u001b[K\rremote: Counting objects:  87% (87/99)\u001b[K\rremote: Counting objects:  88% (88/99)\u001b[K\rremote: Counting objects:  89% (89/99)\u001b[K\rremote: Counting objects:  90% (90/99)\u001b[K\rremote: Counting objects:  91% (91/99)\u001b[K\rremote: Counting objects:  92% (92/99)\u001b[K\rremote: Counting objects:  93% (93/99)\u001b[K\rremote: Counting objects:  94% (94/99)\u001b[K\rremote: Counting objects:  95% (95/99)\u001b[K\rremote: Counting objects:  96% (96/99)\u001b[K\rremote: Counting objects:  97% (97/99)\u001b[K\rremote: Counting objects:  98% (98/99)\u001b[K\rremote: Counting objects: 100% (99/99)\u001b[K\rremote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects:  12% (1/8)\u001b[K\rremote: Compressing objects:  25% (2/8)\u001b[K\rremote: Compressing objects:  37% (3/8)\u001b[K\rremote: Compressing objects:  50% (4/8)\u001b[K\rremote: Compressing objects:  62% (5/8)\u001b[K\rremote: Compressing objects:  75% (6/8)\u001b[K\rremote: Compressing objects:  87% (7/8)\u001b[K\rremote: Compressing objects: 100% (8/8)\u001b[K\rremote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "Receiving objects:   0% (1/235)   \rReceiving objects:   1% (3/235)   \rReceiving objects:   2% (5/235)   \rReceiving objects:   3% (8/235)   \rReceiving objects:   4% (10/235)   \rReceiving objects:   5% (12/235)   \rReceiving objects:   6% (15/235)   \rReceiving objects:   7% (17/235)   \rReceiving objects:   8% (19/235)   \rReceiving objects:   9% (22/235)   \rReceiving objects:  10% (24/235)   \rReceiving objects:  11% (26/235)   \rReceiving objects:  12% (29/235)   \rReceiving objects:  13% (31/235)   \rReceiving objects:  14% (33/235)   \rReceiving objects:  15% (36/235)   \rReceiving objects:  16% (38/235)   \rReceiving objects:  17% (40/235)   \rReceiving objects:  18% (43/235)   \rReceiving objects:  19% (45/235)   \rReceiving objects:  20% (47/235)   \rReceiving objects:  21% (50/235)   \rReceiving objects:  22% (52/235)   \rReceiving objects:  23% (55/235)   \rReceiving objects:  24% (57/235)   \rReceiving objects:  25% (59/235)   \rReceiving objects:  26% (62/235)   \rReceiving objects:  27% (64/235)   \rReceiving objects:  28% (66/235)   \rReceiving objects:  29% (69/235)   \rReceiving objects:  30% (71/235)   \rReceiving objects:  31% (73/235)   \rReceiving objects:  32% (76/235)   \rReceiving objects:  33% (78/235)   \rReceiving objects:  34% (80/235)   \rReceiving objects:  35% (83/235)   \rReceiving objects:  36% (85/235)   \rReceiving objects:  37% (87/235)   \rReceiving objects:  38% (90/235)   \rReceiving objects:  39% (92/235)   \rReceiving objects:  40% (94/235)   \rReceiving objects:  41% (97/235)   \rReceiving objects:  42% (99/235)   \rReceiving objects:  43% (102/235)   \rReceiving objects:  44% (104/235)   \rReceiving objects:  45% (106/235)   \rReceiving objects:  46% (109/235)   \rremote: Total 235 (delta 96), reused 91 (delta 91), pack-reused 136\u001b[K\n",
            "Receiving objects:  47% (111/235)   \rReceiving objects:  48% (113/235)   \rReceiving objects:  49% (116/235)   \rReceiving objects:  50% (118/235)   \rReceiving objects:  51% (120/235)   \rReceiving objects:  52% (123/235)   \rReceiving objects:  53% (125/235)   \rReceiving objects:  54% (127/235)   \rReceiving objects:  55% (130/235)   \rReceiving objects:  56% (132/235)   \rReceiving objects:  57% (134/235)   \rReceiving objects:  58% (137/235)   \rReceiving objects:  59% (139/235)   \rReceiving objects:  60% (141/235)   \rReceiving objects:  61% (144/235)   \rReceiving objects:  62% (146/235)   \rReceiving objects:  63% (149/235)   \rReceiving objects:  64% (151/235)   \rReceiving objects:  65% (153/235)   \rReceiving objects:  66% (156/235)   \rReceiving objects:  67% (158/235)   \rReceiving objects:  68% (160/235)   \rReceiving objects:  69% (163/235)   \rReceiving objects:  70% (165/235)   \rReceiving objects:  71% (167/235)   \rReceiving objects:  72% (170/235)   \rReceiving objects:  73% (172/235)   \rReceiving objects:  74% (174/235)   \rReceiving objects:  75% (177/235)   \rReceiving objects:  76% (179/235)   \rReceiving objects:  77% (181/235)   \rReceiving objects:  78% (184/235)   \rReceiving objects:  79% (186/235)   \rReceiving objects:  80% (188/235)   \rReceiving objects:  81% (191/235)   \rReceiving objects:  82% (193/235)   \rReceiving objects:  83% (196/235)   \rReceiving objects:  84% (198/235)   \rReceiving objects:  85% (200/235)   \rReceiving objects:  86% (203/235)   \rReceiving objects:  87% (205/235)   \rReceiving objects:  88% (207/235)   \rReceiving objects:  89% (210/235)   \rReceiving objects:  90% (212/235)   \rReceiving objects:  91% (214/235)   \rReceiving objects:  92% (217/235)   \rReceiving objects:  93% (219/235)   \rReceiving objects:  94% (221/235)   \rReceiving objects:  95% (224/235)   \rReceiving objects:  96% (226/235)   \rReceiving objects:  97% (228/235)   \rReceiving objects:  98% (231/235)   \rReceiving objects:  99% (233/235)   \rReceiving objects: 100% (235/235)   \rReceiving objects: 100% (235/235), 189.45 KiB | 27.06 MiB/s, done.\n",
            "Resolving deltas:   0% (0/137)   \rResolving deltas:  15% (21/137)   \rResolving deltas:  16% (22/137)   \rResolving deltas:  17% (24/137)   \rResolving deltas:  18% (26/137)   \rResolving deltas:  20% (28/137)   \rResolving deltas:  61% (84/137)   \rResolving deltas:  76% (105/137)   \rResolving deltas:  90% (124/137)   \rResolving deltas: 100% (137/137)   \rResolving deltas: 100% (137/137), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/SynapticMetaplasticityBNN/requirements.txt requirements.txt "
      ],
      "metadata": {
        "id": "gaNAU6ua3oAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze_3L4mU36Tb",
        "outputId": "49034490-a7b9-4b91-861e-874cd067f23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement requirements.txt (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for requirements.txt\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SynapticMetaplasticityBNN/Continual_Learning_Fig-2abcdefgh-3abcd-5cde/main.py --net 'bnn' --hidden-layers 4096 4096 --lr 0.005 --decay 1e-7 --meta 0.0 --epochs-per-task 40 --task-sequence 'pMNIST' 'pMNIST' 'pMNIST' 'pMNIST' 'pMNIST' 'pMNIST'  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ1GxWEI3-Yx",
        "outputId": "ad37e742-ae7b-41a7-a1ec-8b8a5df25be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_pytorch/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "100% 9912422/9912422 [00:00<00:00, 196452858.00it/s]\n",
            "Extracting ./mnist_pytorch/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_pytorch/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_pytorch/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "100% 28881/28881 [00:00<00:00, 146831144.03it/s]\n",
            "Extracting ./mnist_pytorch/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_pytorch/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_pytorch/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "100% 1648877/1648877 [00:00<00:00, 205000337.82it/s]\n",
            "Extracting ./mnist_pytorch/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_pytorch/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_pytorch/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "100% 4542/4542 [00:00<00:00, 29353665.28it/s]\n",
            "Extracting ./mnist_pytorch/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist_pytorch/MNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./fmnist_pytorch/FashionMNIST/raw/train-images-idx3-ubyte.gz\n",
            "100% 26421880/26421880 [00:01<00:00, 19612733.39it/s]\n",
            "Extracting ./fmnist_pytorch/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./fmnist_pytorch/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./fmnist_pytorch/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "100% 29515/29515 [00:00<00:00, 326871.02it/s]\n",
            "Extracting ./fmnist_pytorch/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./fmnist_pytorch/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./fmnist_pytorch/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "100% 4422102/4422102 [00:00<00:00, 6235898.98it/s]\n",
            "Extracting ./fmnist_pytorch/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./fmnist_pytorch/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./fmnist_pytorch/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "100% 5148/5148 [00:00<00:00, 25613614.46it/s]\n",
            "Extracting ./fmnist_pytorch/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./fmnist_pytorch/FashionMNIST/raw\n",
            "\n",
            "BNN(\n",
            "  (layers): ModuleDict(\n",
            "    (fc1): BinarizeLinear(in_features=784, out_features=4096, bias=False)\n",
            "    (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (fc2): BinarizeLinear(in_features=4096, out_features=4096, bias=False)\n",
            "    (bn2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (fc3): BinarizeLinear(in_features=4096, out_features=10, bias=False)\n",
            "    (bn3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "/content/SynapticMetaplasticityBNN/Continual_Learning_Fig-2abcdefgh-3abcd-5cde/models_utils.py:370: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
            "  grad.add_(group['weight_decay'], p.data)\n",
            "Test accuracy: 57848/60000 (96.41%)\n",
            "Test accuracy: 9538/10000 (95.38%)\n",
            "Test accuracy: 58217/60000 (97.03%)\n",
            "Test accuracy: 9617/10000 (96.17%)\n",
            "Test accuracy: 58614/60000 (97.69%)\n",
            "Test accuracy: 9642/10000 (96.42%)\n",
            "Test accuracy: 58978/60000 (98.30%)\n",
            "Test accuracy: 9705/10000 (97.05%)\n",
            "Test accuracy: 59111/60000 (98.52%)\n",
            "Test accuracy: 9693/10000 (96.93%)\n",
            "Test accuracy: 59177/60000 (98.63%)\n",
            "Test accuracy: 9698/10000 (96.98%)\n",
            "Test accuracy: 59396/60000 (98.99%)\n",
            "Test accuracy: 9759/10000 (97.59%)\n",
            "Test accuracy: 59257/60000 (98.76%)\n",
            "Test accuracy: 9716/10000 (97.16%)\n",
            "Test accuracy: 59380/60000 (98.97%)\n",
            "Test accuracy: 9738/10000 (97.38%)\n",
            "Test accuracy: 59500/60000 (99.17%)\n",
            "Test accuracy: 9767/10000 (97.67%)\n",
            "Test accuracy: 59624/60000 (99.37%)\n",
            "Test accuracy: 9769/10000 (97.69%)\n",
            "Test accuracy: 59547/60000 (99.25%)\n",
            "Test accuracy: 9752/10000 (97.52%)\n",
            "Test accuracy: 59645/60000 (99.41%)\n",
            "Test accuracy: 9774/10000 (97.74%)\n",
            "Test accuracy: 59560/60000 (99.27%)\n",
            "Test accuracy: 9760/10000 (97.60%)\n",
            "Test accuracy: 59386/60000 (98.98%)\n",
            "Test accuracy: 9711/10000 (97.11%)\n",
            "Test accuracy: 59371/60000 (98.95%)\n",
            "Test accuracy: 9712/10000 (97.12%)\n",
            "Test accuracy: 59739/60000 (99.56%)\n",
            "Test accuracy: 9763/10000 (97.63%)\n",
            "Test accuracy: 59542/60000 (99.24%)\n",
            "Test accuracy: 9718/10000 (97.18%)\n",
            "Test accuracy: 59555/60000 (99.26%)\n",
            "Test accuracy: 9749/10000 (97.49%)\n",
            "Test accuracy: 59578/60000 (99.30%)\n",
            "Test accuracy: 9716/10000 (97.16%)\n",
            "Test accuracy: 59643/60000 (99.41%)\n",
            "Test accuracy: 9746/10000 (97.46%)\n",
            "Test accuracy: 59287/60000 (98.81%)\n",
            "Test accuracy: 9679/10000 (96.79%)\n",
            "Test accuracy: 59510/60000 (99.18%)\n",
            "Test accuracy: 9703/10000 (97.03%)\n",
            "Test accuracy: 58426/60000 (97.38%)\n",
            "Test accuracy: 9554/10000 (95.54%)\n",
            "Test accuracy: 54759/60000 (91.27%)\n",
            "Test accuracy: 8958/10000 (89.58%)\n",
            "Test accuracy: 51248/60000 (85.41%)\n",
            "Test accuracy: 8397/10000 (83.97%)\n",
            "Test accuracy: 55770/60000 (92.95%)\n",
            "Test accuracy: 9099/10000 (90.99%)\n",
            "Test accuracy: 9292/60000 (15.49%)\n",
            "Test accuracy: 1510/10000 (15.10%)\n",
            "Test accuracy: 17706/60000 (29.51%)\n",
            "Test accuracy: 2880/10000 (28.80%)\n",
            "Test accuracy: 23080/60000 (38.47%)\n",
            "Test accuracy: 3806/10000 (38.06%)\n",
            "Test accuracy: 43976/60000 (73.29%)\n",
            "Test accuracy: 7242/10000 (72.42%)\n",
            "Test accuracy: 51651/60000 (86.08%)\n",
            "Test accuracy: 8448/10000 (84.48%)\n",
            "Test accuracy: 46217/60000 (77.03%)\n",
            "Test accuracy: 7600/10000 (76.00%)\n",
            "Test accuracy: 17675/60000 (29.46%)\n",
            "Test accuracy: 2899/10000 (28.99%)\n",
            "Test accuracy: 40252/60000 (67.09%)\n",
            "Test accuracy: 6644/10000 (66.44%)\n",
            "Test accuracy: 32405/60000 (54.01%)\n",
            "Test accuracy: 5288/10000 (52.88%)\n",
            "Test accuracy: 12218/60000 (20.36%)\n",
            "Test accuracy: 2018/10000 (20.18%)\n",
            "Test accuracy: 42895/60000 (71.49%)\n",
            "Test accuracy: 7092/10000 (70.92%)\n",
            "Test accuracy: 5842/60000 (9.74%)\n",
            "Test accuracy: 982/10000 (9.82%)\n",
            "Test accuracy: 12875/60000 (21.46%)\n",
            "Test accuracy: 2147/10000 (21.47%)\n",
            "Test accuracy: 47974/60000 (79.96%)\n",
            "Test accuracy: 7935/10000 (79.35%)\n",
            "Test accuracy: 49058/60000 (81.76%)\n",
            "Test accuracy: 8091/10000 (80.91%)\n",
            "Test accuracy: 6268/60000 (10.45%)\n",
            "Test accuracy: 1028/10000 (10.28%)\n",
            "Test accuracy: 7428/60000 (12.38%)\n",
            "Test accuracy: 1264/10000 (12.64%)\n",
            "Test accuracy: 5842/60000 (9.74%)\n",
            "Test accuracy: 982/10000 (9.82%)\n",
            "Test accuracy: 6452/60000 (10.75%)\n",
            "Test accuracy: 1077/10000 (10.77%)\n",
            "Test accuracy: 11738/60000 (19.56%)\n",
            "Test accuracy: 1941/10000 (19.41%)\n",
            "Test accuracy: 5923/60000 (9.87%)\n",
            "Test accuracy: 980/10000 (9.80%)\n",
            "Test accuracy: 6124/60000 (10.21%)\n",
            "Test accuracy: 1013/10000 (10.13%)\n",
            "Test accuracy: 6291/60000 (10.48%)\n",
            "Test accuracy: 1034/10000 (10.34%)\n",
            "Test accuracy: 36397/60000 (60.66%)\n",
            "Test accuracy: 6074/10000 (60.74%)\n",
            "Test accuracy: 5918/60000 (9.86%)\n",
            "Test accuracy: 958/10000 (9.58%)\n",
            "Test accuracy: 5421/60000 (9.04%)\n",
            "Test accuracy: 892/10000 (8.92%)\n",
            "Test accuracy: 5918/60000 (9.86%)\n",
            "Test accuracy: 958/10000 (9.58%)\n",
            "Test accuracy: 5923/60000 (9.87%)\n",
            "Test accuracy: 980/10000 (9.80%)\n",
            "Test accuracy: 5421/60000 (9.04%)\n",
            "Test accuracy: 892/10000 (8.92%)\n",
            "Test accuracy: 36063/60000 (60.10%)\n",
            "Test accuracy: 5863/10000 (58.63%)\n",
            "Test accuracy: 6547/60000 (10.91%)\n",
            "Test accuracy: 1087/10000 (10.87%)\n",
            "Test accuracy: 5842/60000 (9.74%)\n",
            "Test accuracy: 982/10000 (9.82%)\n",
            "Test accuracy: 23513/60000 (39.19%)\n",
            "Test accuracy: 3891/10000 (38.91%)\n",
            "Test accuracy: 40217/60000 (67.03%)\n",
            "Test accuracy: 6532/10000 (65.32%)\n",
            "Test accuracy: 15358/60000 (25.60%)\n",
            "Test accuracy: 2519/10000 (25.19%)\n",
            "Test accuracy: 29720/60000 (49.53%)\n",
            "Test accuracy: 4869/10000 (48.69%)\n",
            "Test accuracy: 12658/60000 (21.10%)\n",
            "Test accuracy: 2089/10000 (20.89%)\n",
            "Test accuracy: 35578/60000 (59.30%)\n",
            "Test accuracy: 5860/10000 (58.60%)\n",
            "Test accuracy: 14329/60000 (23.88%)\n",
            "Test accuracy: 2426/10000 (24.26%)\n",
            "Test accuracy: 48995/60000 (81.66%)\n",
            "Test accuracy: 7960/10000 (79.60%)\n",
            "Test accuracy: 8890/60000 (14.82%)\n",
            "Test accuracy: 1495/10000 (14.95%)\n",
            "Test accuracy: 13338/60000 (22.23%)\n",
            "Test accuracy: 2198/10000 (21.98%)\n",
            "Test accuracy: 51347/60000 (85.58%)\n",
            "Test accuracy: 8383/10000 (83.83%)\n",
            "Test accuracy: 38189/60000 (63.65%)\n",
            "Test accuracy: 6191/10000 (61.91%)\n",
            "Test accuracy: 50611/60000 (84.35%)\n",
            "Test accuracy: 8261/10000 (82.61%)\n",
            "Test accuracy: 12201/60000 (20.34%)\n",
            "Test accuracy: 2016/10000 (20.16%)\n",
            "Test accuracy: 24572/60000 (40.95%)\n",
            "Test accuracy: 4124/10000 (41.24%)\n",
            "Test accuracy: 26898/60000 (44.83%)\n",
            "Test accuracy: 4439/10000 (44.39%)\n",
            "Test accuracy: 26506/60000 (44.18%)\n",
            "Test accuracy: 4296/10000 (42.96%)\n",
            "Test accuracy: 49581/60000 (82.64%)\n",
            "Test accuracy: 8080/10000 (80.80%)\n",
            "Test accuracy: 21353/60000 (35.59%)\n",
            "Test accuracy: 3520/10000 (35.20%)\n",
            "Test accuracy: 52958/60000 (88.26%)\n",
            "Test accuracy: 8657/10000 (86.57%)\n",
            "Test accuracy: 31609/60000 (52.68%)\n",
            "Test accuracy: 5022/10000 (50.22%)\n",
            "Test accuracy: 53744/60000 (89.57%)\n",
            "Test accuracy: 8904/10000 (89.04%)\n",
            "Test accuracy: 57524/60000 (95.87%)\n",
            "Test accuracy: 9467/10000 (94.67%)\n",
            "Test accuracy: 58829/60000 (98.05%)\n",
            "Test accuracy: 9650/10000 (96.50%)\n",
            "Test accuracy: 52401/60000 (87.33%)\n",
            "Test accuracy: 8648/10000 (86.48%)\n",
            "Test accuracy: 56012/60000 (93.35%)\n",
            "Test accuracy: 9252/10000 (92.52%)\n",
            "Test accuracy: 53056/60000 (88.43%)\n",
            "Test accuracy: 8747/10000 (87.47%)\n",
            "Test accuracy: 45922/60000 (76.54%)\n",
            "Test accuracy: 7605/10000 (76.05%)\n",
            "Test accuracy: 50780/60000 (84.63%)\n",
            "Test accuracy: 8287/10000 (82.87%)\n",
            "Test accuracy: 58599/60000 (97.67%)\n",
            "Test accuracy: 9594/10000 (95.94%)\n",
            "Test accuracy: 58964/60000 (98.27%)\n",
            "Test accuracy: 9643/10000 (96.43%)\n",
            "Test accuracy: 58670/60000 (97.78%)\n",
            "Test accuracy: 9598/10000 (95.98%)\n",
            "Test accuracy: 56621/60000 (94.37%)\n",
            "Test accuracy: 9240/10000 (92.40%)\n",
            "Test accuracy: 45226/60000 (75.38%)\n",
            "Test accuracy: 7469/10000 (74.69%)\n",
            "Test accuracy: 58789/60000 (97.98%)\n",
            "Test accuracy: 9627/10000 (96.27%)\n",
            "Test accuracy: 59478/60000 (99.13%)\n",
            "Test accuracy: 9701/10000 (97.01%)\n",
            "Test accuracy: 53037/60000 (88.39%)\n",
            "Test accuracy: 8703/10000 (87.03%)\n",
            "Test accuracy: 59500/60000 (99.17%)\n",
            "Test accuracy: 9702/10000 (97.02%)\n",
            "Test accuracy: 57858/60000 (96.43%)\n",
            "Test accuracy: 9452/10000 (94.52%)\n",
            "Test accuracy: 56378/60000 (93.96%)\n",
            "Test accuracy: 9193/10000 (91.93%)\n",
            "Test accuracy: 59162/60000 (98.60%)\n",
            "Test accuracy: 9663/10000 (96.63%)\n",
            "Test accuracy: 57231/60000 (95.39%)\n",
            "Test accuracy: 9390/10000 (93.90%)\n",
            "Test accuracy: 58429/60000 (97.38%)\n",
            "Test accuracy: 9527/10000 (95.27%)\n",
            "Test accuracy: 58911/60000 (98.19%)\n",
            "Test accuracy: 9589/10000 (95.89%)\n",
            "Test accuracy: 58321/60000 (97.20%)\n",
            "Test accuracy: 9545/10000 (95.45%)\n",
            "Test accuracy: 57720/60000 (96.20%)\n",
            "Test accuracy: 9438/10000 (94.38%)\n",
            "Test accuracy: 58726/60000 (97.88%)\n",
            "Test accuracy: 9596/10000 (95.96%)\n",
            "Test accuracy: 59155/60000 (98.59%)\n",
            "Test accuracy: 9643/10000 (96.43%)\n",
            "Test accuracy: 59204/60000 (98.67%)\n",
            "Test accuracy: 9650/10000 (96.50%)\n",
            "Test accuracy: 59452/60000 (99.09%)\n",
            "Test accuracy: 9681/10000 (96.81%)\n",
            "Test accuracy: 58355/60000 (97.26%)\n",
            "Test accuracy: 9501/10000 (95.01%)\n",
            "Test accuracy: 59468/60000 (99.11%)\n",
            "Test accuracy: 9684/10000 (96.84%)\n",
            "Test accuracy: 58418/60000 (97.36%)\n",
            "Test accuracy: 9528/10000 (95.28%)\n",
            "Test accuracy: 59213/60000 (98.69%)\n",
            "Test accuracy: 9624/10000 (96.24%)\n",
            "Test accuracy: 59075/60000 (98.46%)\n",
            "Test accuracy: 9620/10000 (96.20%)\n",
            "Test accuracy: 59515/60000 (99.19%)\n",
            "Test accuracy: 9683/10000 (96.83%)\n",
            "Test accuracy: 59288/60000 (98.81%)\n",
            "Test accuracy: 9646/10000 (96.46%)\n",
            "Test accuracy: 58808/60000 (98.01%)\n",
            "Test accuracy: 9620/10000 (96.20%)\n",
            "Test accuracy: 59345/60000 (98.91%)\n",
            "Test accuracy: 9688/10000 (96.88%)\n",
            "Test accuracy: 59662/60000 (99.44%)\n",
            "Test accuracy: 9730/10000 (97.30%)\n",
            "Test accuracy: 59463/60000 (99.11%)\n",
            "Test accuracy: 9681/10000 (96.81%)\n",
            "Test accuracy: 58072/60000 (96.79%)\n",
            "Test accuracy: 9583/10000 (95.83%)\n",
            "Test accuracy: 58492/60000 (97.49%)\n",
            "Test accuracy: 9596/10000 (95.96%)\n",
            "Test accuracy: 58220/60000 (97.03%)\n",
            "Test accuracy: 9564/10000 (95.64%)\n",
            "Test accuracy: 58858/60000 (98.10%)\n",
            "Test accuracy: 9632/10000 (96.32%)\n",
            "Test accuracy: 58667/60000 (97.78%)\n",
            "Test accuracy: 9556/10000 (95.56%)\n",
            "Test accuracy: 59241/60000 (98.73%)\n",
            "Test accuracy: 9687/10000 (96.87%)\n",
            "Test accuracy: 59390/60000 (98.98%)\n",
            "Test accuracy: 9728/10000 (97.28%)\n",
            "Test accuracy: 59414/60000 (99.02%)\n",
            "Test accuracy: 9749/10000 (97.49%)\n",
            "Test accuracy: 59348/60000 (98.91%)\n",
            "Test accuracy: 9704/10000 (97.04%)\n",
            "Test accuracy: 59288/60000 (98.81%)\n",
            "Test accuracy: 9704/10000 (97.04%)\n",
            "Test accuracy: 59315/60000 (98.86%)\n",
            "Test accuracy: 9678/10000 (96.78%)\n",
            "Test accuracy: 59450/60000 (99.08%)\n",
            "Test accuracy: 9702/10000 (97.02%)\n",
            "Test accuracy: 59479/60000 (99.13%)\n",
            "Test accuracy: 9715/10000 (97.15%)\n",
            "Test accuracy: 59424/60000 (99.04%)\n",
            "Test accuracy: 9741/10000 (97.41%)\n",
            "Test accuracy: 59746/60000 (99.58%)\n",
            "Test accuracy: 9778/10000 (97.78%)\n",
            "Test accuracy: 59361/60000 (98.94%)\n",
            "Test accuracy: 9681/10000 (96.81%)\n",
            "Test accuracy: 59169/60000 (98.61%)\n",
            "Test accuracy: 9653/10000 (96.53%)\n",
            "Test accuracy: 59607/60000 (99.34%)\n",
            "Test accuracy: 9728/10000 (97.28%)\n",
            "Test accuracy: 59762/60000 (99.60%)\n",
            "Test accuracy: 9783/10000 (97.83%)\n",
            "Test accuracy: 59305/60000 (98.84%)\n",
            "Test accuracy: 9660/10000 (96.60%)\n",
            "Test accuracy: 59693/60000 (99.49%)\n",
            "Test accuracy: 9744/10000 (97.44%)\n",
            "Test accuracy: 59622/60000 (99.37%)\n",
            "Test accuracy: 9737/10000 (97.37%)\n",
            "Test accuracy: 59598/60000 (99.33%)\n",
            "Test accuracy: 9722/10000 (97.22%)\n",
            "Test accuracy: 59201/60000 (98.67%)\n",
            "Test accuracy: 9680/10000 (96.80%)\n",
            "Test accuracy: 59615/60000 (99.36%)\n",
            "Test accuracy: 9709/10000 (97.09%)\n",
            "Test accuracy: 59122/60000 (98.54%)\n",
            "Test accuracy: 9641/10000 (96.41%)\n",
            "Test accuracy: 59459/60000 (99.10%)\n",
            "Test accuracy: 9698/10000 (96.98%)\n",
            "Test accuracy: 59709/60000 (99.52%)\n",
            "Test accuracy: 9722/10000 (97.22%)\n",
            "Test accuracy: 59691/60000 (99.48%)\n",
            "Test accuracy: 9729/10000 (97.29%)\n",
            "Test accuracy: 59597/60000 (99.33%)\n",
            "Test accuracy: 9706/10000 (97.06%)\n",
            "Test accuracy: 59816/60000 (99.69%)\n",
            "Test accuracy: 9780/10000 (97.80%)\n",
            "Test accuracy: 59386/60000 (98.98%)\n",
            "Test accuracy: 9701/10000 (97.01%)\n",
            "Test accuracy: 59715/60000 (99.53%)\n",
            "Test accuracy: 9767/10000 (97.67%)\n",
            "Test accuracy: 59698/60000 (99.50%)\n",
            "Test accuracy: 9764/10000 (97.64%)\n",
            "Test accuracy: 59633/60000 (99.39%)\n",
            "Test accuracy: 9725/10000 (97.25%)\n",
            "Test accuracy: 59647/60000 (99.41%)\n",
            "Test accuracy: 9741/10000 (97.41%)\n",
            "Test accuracy: 59717/60000 (99.53%)\n",
            "Test accuracy: 9762/10000 (97.62%)\n",
            "Test accuracy: 59549/60000 (99.25%)\n",
            "Test accuracy: 9725/10000 (97.25%)\n",
            "Test accuracy: 59750/60000 (99.58%)\n",
            "Test accuracy: 9744/10000 (97.44%)\n",
            "Test accuracy: 59843/60000 (99.74%)\n",
            "Test accuracy: 9771/10000 (97.71%)\n",
            "Test accuracy: 57789/60000 (96.31%)\n",
            "Test accuracy: 9508/10000 (95.08%)\n",
            "Test accuracy: 58810/60000 (98.02%)\n",
            "Test accuracy: 9654/10000 (96.54%)\n",
            "Test accuracy: 58922/60000 (98.20%)\n",
            "Test accuracy: 9650/10000 (96.50%)\n",
            "Test accuracy: 59190/60000 (98.65%)\n",
            "Test accuracy: 9685/10000 (96.85%)\n",
            "Test accuracy: 58971/60000 (98.28%)\n",
            "Test accuracy: 9643/10000 (96.43%)\n",
            "Test accuracy: 59288/60000 (98.81%)\n",
            "Test accuracy: 9712/10000 (97.12%)\n",
            "Test accuracy: 59324/60000 (98.87%)\n",
            "Test accuracy: 9702/10000 (97.02%)\n",
            "Test accuracy: 59268/60000 (98.78%)\n",
            "Test accuracy: 9660/10000 (96.60%)\n",
            "Test accuracy: 59172/60000 (98.62%)\n",
            "Test accuracy: 9666/10000 (96.66%)\n",
            "Test accuracy: 59251/60000 (98.75%)\n",
            "Test accuracy: 9714/10000 (97.14%)\n",
            "Test accuracy: 59634/60000 (99.39%)\n",
            "Test accuracy: 9752/10000 (97.52%)\n",
            "Test accuracy: 59331/60000 (98.89%)\n",
            "Test accuracy: 9710/10000 (97.10%)\n",
            "Test accuracy: 59517/60000 (99.19%)\n",
            "Test accuracy: 9729/10000 (97.29%)\n",
            "Test accuracy: 59747/60000 (99.58%)\n",
            "Test accuracy: 9756/10000 (97.56%)\n",
            "Test accuracy: 59471/60000 (99.12%)\n",
            "Test accuracy: 9726/10000 (97.26%)\n",
            "Test accuracy: 59387/60000 (98.98%)\n",
            "Test accuracy: 9672/10000 (96.72%)\n",
            "Test accuracy: 59717/60000 (99.53%)\n",
            "Test accuracy: 9764/10000 (97.64%)\n",
            "Test accuracy: 59720/60000 (99.53%)\n",
            "Test accuracy: 9787/10000 (97.87%)\n",
            "Test accuracy: 59469/60000 (99.11%)\n",
            "Test accuracy: 9702/10000 (97.02%)\n",
            "Test accuracy: 59663/60000 (99.44%)\n",
            "Test accuracy: 9723/10000 (97.23%)\n",
            "Test accuracy: 59766/60000 (99.61%)\n",
            "Test accuracy: 9757/10000 (97.57%)\n",
            "Test accuracy: 59737/60000 (99.56%)\n",
            "Test accuracy: 9772/10000 (97.72%)\n",
            "Test accuracy: 59573/60000 (99.29%)\n",
            "Test accuracy: 9727/10000 (97.27%)\n",
            "Test accuracy: 59740/60000 (99.57%)\n",
            "Test accuracy: 9765/10000 (97.65%)\n",
            "Test accuracy: 59716/60000 (99.53%)\n",
            "Test accuracy: 9770/10000 (97.70%)\n",
            "Test accuracy: 59630/60000 (99.38%)\n",
            "Test accuracy: 9731/10000 (97.31%)\n",
            "Test accuracy: 59590/60000 (99.32%)\n",
            "Test accuracy: 9719/10000 (97.19%)\n",
            "Test accuracy: 59528/60000 (99.21%)\n",
            "Test accuracy: 9701/10000 (97.01%)\n",
            "Test accuracy: 59524/60000 (99.21%)\n",
            "Test accuracy: 9725/10000 (97.25%)\n",
            "Test accuracy: 59691/60000 (99.48%)\n",
            "Test accuracy: 9740/10000 (97.40%)\n",
            "Test accuracy: 59719/60000 (99.53%)\n",
            "Test accuracy: 9761/10000 (97.61%)\n",
            "Test accuracy: 59811/60000 (99.69%)\n",
            "Test accuracy: 9759/10000 (97.59%)\n",
            "Test accuracy: 59702/60000 (99.50%)\n",
            "Test accuracy: 9755/10000 (97.55%)\n",
            "Test accuracy: 59767/60000 (99.61%)\n",
            "Test accuracy: 9737/10000 (97.37%)\n",
            "Test accuracy: 59737/60000 (99.56%)\n",
            "Test accuracy: 9758/10000 (97.58%)\n",
            "Test accuracy: 59554/60000 (99.26%)\n",
            "Test accuracy: 9719/10000 (97.19%)\n",
            "Test accuracy: 59648/60000 (99.41%)\n",
            "Test accuracy: 9746/10000 (97.46%)\n",
            "Test accuracy: 59564/60000 (99.27%)\n",
            "Test accuracy: 9723/10000 (97.23%)\n",
            "Test accuracy: 59757/60000 (99.59%)\n",
            "Test accuracy: 9759/10000 (97.59%)\n",
            "Test accuracy: 59646/60000 (99.41%)\n",
            "Test accuracy: 9718/10000 (97.18%)\n",
            "Test accuracy: 58165/60000 (96.94%)\n",
            "Test accuracy: 9575/10000 (95.75%)\n",
            "Test accuracy: 58697/60000 (97.83%)\n",
            "Test accuracy: 9641/10000 (96.41%)\n",
            "Test accuracy: 58919/60000 (98.20%)\n",
            "Test accuracy: 9657/10000 (96.57%)\n",
            "Test accuracy: 59108/60000 (98.51%)\n",
            "Test accuracy: 9713/10000 (97.13%)\n",
            "Test accuracy: 59108/60000 (98.51%)\n",
            "Test accuracy: 9690/10000 (96.90%)\n",
            "Test accuracy: 59250/60000 (98.75%)\n",
            "Test accuracy: 9686/10000 (96.86%)\n",
            "Test accuracy: 59362/60000 (98.94%)\n",
            "Test accuracy: 9744/10000 (97.44%)\n",
            "Test accuracy: 59493/60000 (99.16%)\n",
            "Test accuracy: 9722/10000 (97.22%)\n",
            "Test accuracy: 59341/60000 (98.90%)\n",
            "Test accuracy: 9680/10000 (96.80%)\n",
            "Test accuracy: 59458/60000 (99.10%)\n",
            "Test accuracy: 9750/10000 (97.50%)\n",
            "Test accuracy: 59479/60000 (99.13%)\n",
            "Test accuracy: 9740/10000 (97.40%)\n",
            "Test accuracy: 59374/60000 (98.96%)\n",
            "Test accuracy: 9660/10000 (96.60%)\n",
            "Test accuracy: 59587/60000 (99.31%)\n",
            "Test accuracy: 9751/10000 (97.51%)\n",
            "Test accuracy: 59434/60000 (99.06%)\n",
            "Test accuracy: 9716/10000 (97.16%)\n",
            "Test accuracy: 59639/60000 (99.40%)\n",
            "Test accuracy: 9744/10000 (97.44%)\n",
            "Test accuracy: 59599/60000 (99.33%)\n",
            "Test accuracy: 9708/10000 (97.08%)\n",
            "Test accuracy: 59459/60000 (99.10%)\n",
            "Test accuracy: 9720/10000 (97.20%)\n",
            "Test accuracy: 59592/60000 (99.32%)\n",
            "Test accuracy: 9717/10000 (97.17%)\n",
            "Test accuracy: 59425/60000 (99.04%)\n",
            "Test accuracy: 9716/10000 (97.16%)\n",
            "Test accuracy: 59729/60000 (99.55%)\n",
            "Test accuracy: 9757/10000 (97.57%)\n",
            "Test accuracy: 59618/60000 (99.36%)\n",
            "Test accuracy: 9741/10000 (97.41%)\n",
            "Test accuracy: 59537/60000 (99.23%)\n",
            "Test accuracy: 9718/10000 (97.18%)\n",
            "Test accuracy: 59388/60000 (98.98%)\n",
            "Test accuracy: 9700/10000 (97.00%)\n",
            "Test accuracy: 59754/60000 (99.59%)\n",
            "Test accuracy: 9778/10000 (97.78%)\n",
            "Test accuracy: 59737/60000 (99.56%)\n",
            "Test accuracy: 9763/10000 (97.63%)\n",
            "Test accuracy: 59041/60000 (98.40%)\n",
            "Test accuracy: 9624/10000 (96.24%)\n",
            "Test accuracy: 59553/60000 (99.25%)\n",
            "Test accuracy: 9693/10000 (96.93%)\n",
            "Test accuracy: 59736/60000 (99.56%)\n",
            "Test accuracy: 9757/10000 (97.57%)\n",
            "Test accuracy: 59742/60000 (99.57%)\n",
            "Test accuracy: 9741/10000 (97.41%)\n",
            "Test accuracy: 59697/60000 (99.50%)\n",
            "Test accuracy: 9727/10000 (97.27%)\n",
            "Test accuracy: 59541/60000 (99.23%)\n",
            "Test accuracy: 9734/10000 (97.34%)\n",
            "Test accuracy: 59734/60000 (99.56%)\n",
            "Test accuracy: 9757/10000 (97.57%)\n",
            "Test accuracy: 59743/60000 (99.57%)\n",
            "Test accuracy: 9774/10000 (97.74%)\n",
            "Test accuracy: 59788/60000 (99.65%)\n",
            "Test accuracy: 9786/10000 (97.86%)\n",
            "Test accuracy: 59507/60000 (99.18%)\n",
            "Test accuracy: 9716/10000 (97.16%)\n",
            "Test accuracy: 59826/60000 (99.71%)\n",
            "Test accuracy: 9767/10000 (97.67%)\n",
            "Test accuracy: 59827/60000 (99.71%)\n",
            "Test accuracy: 9779/10000 (97.79%)\n",
            "Test accuracy: 59546/60000 (99.24%)\n",
            "Test accuracy: 9691/10000 (96.91%)\n",
            "Test accuracy: 59729/60000 (99.55%)\n",
            "Test accuracy: 9756/10000 (97.56%)\n",
            "Test accuracy: 59677/60000 (99.46%)\n",
            "Test accuracy: 9737/10000 (97.37%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SynapticMetaplasticityBNN/Continual_Learning_Fig-2abcdefgh-3abcd-5cde/main.py --net 'bnn' --hidden-layers 4096 4096 --lr 0.005 --decay 1e-7 --meta 1.35 --epochs-per-task 40 --task-sequence 'pMNIST' 'pMNIST' 'pMNIST' 'pMNIST' 'pMNIST' 'pMNIST'  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFqHFFZX4XV7",
        "outputId": "2d0077fc-eb59-4c0e-8862-cba1215cd2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BNN(\n",
            "  (layers): ModuleDict(\n",
            "    (fc1): BinarizeLinear(in_features=784, out_features=4096, bias=False)\n",
            "    (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (fc2): BinarizeLinear(in_features=4096, out_features=4096, bias=False)\n",
            "    (bn2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (fc3): BinarizeLinear(in_features=4096, out_features=10, bias=False)\n",
            "    (bn3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "/content/SynapticMetaplasticityBNN/Continual_Learning_Fig-2abcdefgh-3abcd-5cde/models_utils.py:370: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
            "  grad.add_(group['weight_decay'], p.data)\n",
            "Test accuracy: 57851/60000 (96.42%)\n",
            "Test accuracy: 9582/10000 (95.82%)\n",
            "Test accuracy: 58558/60000 (97.60%)\n",
            "Test accuracy: 9659/10000 (96.59%)\n",
            "Test accuracy: 58823/60000 (98.04%)\n",
            "Test accuracy: 9672/10000 (96.72%)\n",
            "Test accuracy: 59017/60000 (98.36%)\n",
            "Test accuracy: 9713/10000 (97.13%)\n",
            "Test accuracy: 59124/60000 (98.54%)\n",
            "Test accuracy: 9731/10000 (97.31%)\n",
            "Test accuracy: 59172/60000 (98.62%)\n",
            "Test accuracy: 9726/10000 (97.26%)\n",
            "Test accuracy: 59446/60000 (99.08%)\n",
            "Test accuracy: 9740/10000 (97.40%)\n",
            "Test accuracy: 59362/60000 (98.94%)\n",
            "Test accuracy: 9739/10000 (97.39%)\n",
            "Test accuracy: 59569/60000 (99.28%)\n",
            "Test accuracy: 9758/10000 (97.58%)\n",
            "Test accuracy: 59553/60000 (99.25%)\n",
            "Test accuracy: 9742/10000 (97.42%)\n",
            "Test accuracy: 59666/60000 (99.44%)\n",
            "Test accuracy: 9758/10000 (97.58%)\n",
            "Test accuracy: 59602/60000 (99.34%)\n",
            "Test accuracy: 9715/10000 (97.15%)\n",
            "Test accuracy: 59791/60000 (99.65%)\n",
            "Test accuracy: 9782/10000 (97.82%)\n",
            "Test accuracy: 59752/60000 (99.59%)\n",
            "Test accuracy: 9751/10000 (97.51%)\n",
            "Test accuracy: 59847/60000 (99.75%)\n",
            "Test accuracy: 9768/10000 (97.68%)\n",
            "Test accuracy: 59761/60000 (99.60%)\n",
            "Test accuracy: 9757/10000 (97.57%)\n",
            "Test accuracy: 59813/60000 (99.69%)\n",
            "Test accuracy: 9753/10000 (97.53%)\n",
            "Test accuracy: 59718/60000 (99.53%)\n",
            "Test accuracy: 9745/10000 (97.45%)\n",
            "Test accuracy: 59609/60000 (99.35%)\n",
            "Test accuracy: 9711/10000 (97.11%)\n",
            "Test accuracy: 59844/60000 (99.74%)\n",
            "Test accuracy: 9773/10000 (97.73%)\n",
            "Test accuracy: 59680/60000 (99.47%)\n",
            "Test accuracy: 9705/10000 (97.05%)\n",
            "Test accuracy: 59595/60000 (99.33%)\n",
            "Test accuracy: 9676/10000 (96.76%)\n",
            "Test accuracy: 59491/60000 (99.15%)\n",
            "Test accuracy: 9682/10000 (96.82%)\n",
            "Test accuracy: 59643/60000 (99.41%)\n",
            "Test accuracy: 9690/10000 (96.90%)\n",
            "Test accuracy: 49382/60000 (82.30%)\n",
            "Test accuracy: 7995/10000 (79.95%)\n",
            "Test accuracy: 57293/60000 (95.49%)\n",
            "Test accuracy: 9307/10000 (93.07%)\n",
            "Test accuracy: 57247/60000 (95.41%)\n",
            "Test accuracy: 9246/10000 (92.46%)\n",
            "Test accuracy: 57949/60000 (96.58%)\n",
            "Test accuracy: 9412/10000 (94.12%)\n",
            "Test accuracy: 59185/60000 (98.64%)\n",
            "Test accuracy: 9609/10000 (96.09%)\n",
            "Test accuracy: 5918/60000 (9.86%)\n",
            "Test accuracy: 958/10000 (9.58%)\n",
            "Test accuracy: 6742/60000 (11.24%)\n",
            "Test accuracy: 1135/10000 (11.35%)\n",
            "Test accuracy: 6625/60000 (11.04%)\n",
            "Test accuracy: 1083/10000 (10.83%)\n",
            "Test accuracy: 30097/60000 (50.16%)\n",
            "Test accuracy: 4946/10000 (49.46%)\n",
            "Test accuracy: 27356/60000 (45.59%)\n",
            "Test accuracy: 4448/10000 (44.48%)\n",
            "Test accuracy: 17839/60000 (29.73%)\n",
            "Test accuracy: 2992/10000 (29.92%)\n",
            "Test accuracy: 18132/60000 (30.22%)\n",
            "Test accuracy: 3038/10000 (30.38%)\n",
            "Test accuracy: 5842/60000 (9.74%)\n",
            "Test accuracy: 982/10000 (9.82%)\n",
            "Test accuracy: 15151/60000 (25.25%)\n",
            "Test accuracy: 2570/10000 (25.70%)\n",
            "Test accuracy: 8268/60000 (13.78%)\n",
            "Test accuracy: 1330/10000 (13.30%)\n",
            "Test accuracy: 54991/60000 (91.65%)\n",
            "Test accuracy: 8873/10000 (88.73%)\n",
            "Test accuracy: 5918/60000 (9.86%)\n",
            "Test accuracy: 958/10000 (9.58%)\n",
            "Test accuracy: 33275/60000 (55.46%)\n",
            "Test accuracy: 5565/10000 (55.65%)\n",
            "Test accuracy: 13702/60000 (22.84%)\n",
            "Test accuracy: 2268/10000 (22.68%)\n",
            "Test accuracy: 44981/60000 (74.97%)\n",
            "Test accuracy: 7532/10000 (75.32%)\n",
            "Test accuracy: 5958/60000 (9.93%)\n",
            "Test accuracy: 1032/10000 (10.32%)\n",
            "Test accuracy: 5919/60000 (9.87%)\n",
            "Test accuracy: 958/10000 (9.58%)\n",
            "Test accuracy: 5973/60000 (9.96%)\n",
            "Test accuracy: 1036/10000 (10.36%)\n",
            "Test accuracy: 37782/60000 (62.97%)\n",
            "Test accuracy: 6197/10000 (61.97%)\n",
            "Test accuracy: 19098/60000 (31.83%)\n",
            "Test accuracy: 3204/10000 (32.04%)\n",
            "Test accuracy: 46646/60000 (77.74%)\n",
            "Test accuracy: 7515/10000 (75.15%)\n",
            "Test accuracy: 6131/60000 (10.22%)\n",
            "Test accuracy: 1010/10000 (10.10%)\n",
            "Test accuracy: 16299/60000 (27.16%)\n",
            "Test accuracy: 2621/10000 (26.21%)\n",
            "Test accuracy: 56889/60000 (94.81%)\n",
            "Test accuracy: 9231/10000 (92.31%)\n",
            "Test accuracy: 30654/60000 (51.09%)\n",
            "Test accuracy: 4975/10000 (49.75%)\n",
            "Test accuracy: 18791/60000 (31.32%)\n",
            "Test accuracy: 3098/10000 (30.98%)\n",
            "Test accuracy: 15723/60000 (26.20%)\n",
            "Test accuracy: 2516/10000 (25.16%)\n",
            "Test accuracy: 41670/60000 (69.45%)\n",
            "Test accuracy: 6864/10000 (68.64%)\n",
            "Test accuracy: 12085/60000 (20.14%)\n",
            "Test accuracy: 2015/10000 (20.15%)\n",
            "Test accuracy: 37014/60000 (61.69%)\n",
            "Test accuracy: 6010/10000 (60.10%)\n",
            "Test accuracy: 10735/60000 (17.89%)\n",
            "Test accuracy: 1767/10000 (17.67%)\n",
            "Test accuracy: 11897/60000 (19.83%)\n",
            "Test accuracy: 1944/10000 (19.44%)\n",
            "Test accuracy: 11630/60000 (19.38%)\n",
            "Test accuracy: 1945/10000 (19.45%)\n",
            "Test accuracy: 52500/60000 (87.50%)\n",
            "Test accuracy: 8552/10000 (85.52%)\n",
            "Test accuracy: 13429/60000 (22.38%)\n",
            "Test accuracy: 2235/10000 (22.35%)\n",
            "Test accuracy: 14818/60000 (24.70%)\n",
            "Test accuracy: 2436/10000 (24.36%)\n",
            "Test accuracy: 5888/60000 (9.81%)\n",
            "Test accuracy: 985/10000 (9.85%)\n",
            "Test accuracy: 6742/60000 (11.24%)\n",
            "Test accuracy: 1135/10000 (11.35%)\n",
            "Test accuracy: 50016/60000 (83.36%)\n",
            "Test accuracy: 8144/10000 (81.44%)\n",
            "Test accuracy: 21067/60000 (35.11%)\n",
            "Test accuracy: 3519/10000 (35.19%)\n",
            "Test accuracy: 51997/60000 (86.66%)\n",
            "Test accuracy: 8442/10000 (84.42%)\n",
            "Test accuracy: 8742/60000 (14.57%)\n",
            "Test accuracy: 1412/10000 (14.12%)\n",
            "Test accuracy: 53005/60000 (88.34%)\n",
            "Test accuracy: 8486/10000 (84.86%)\n",
            "Test accuracy: 44423/60000 (74.04%)\n",
            "Test accuracy: 7160/10000 (71.60%)\n",
            "Test accuracy: 24395/60000 (40.66%)\n",
            "Test accuracy: 4194/10000 (41.94%)\n",
            "Test accuracy: 50774/60000 (84.62%)\n",
            "Test accuracy: 8302/10000 (83.02%)\n",
            "Test accuracy: 58845/60000 (98.08%)\n",
            "Test accuracy: 9529/10000 (95.29%)\n",
            "Test accuracy: 50995/60000 (84.99%)\n",
            "Test accuracy: 8310/10000 (83.10%)\n",
            "Test accuracy: 36236/60000 (60.39%)\n",
            "Test accuracy: 5897/10000 (58.97%)\n",
            "Test accuracy: 21719/60000 (36.20%)\n",
            "Test accuracy: 3621/10000 (36.21%)\n",
            "Test accuracy: 40282/60000 (67.14%)\n",
            "Test accuracy: 6450/10000 (64.50%)\n",
            "Test accuracy: 52826/60000 (88.04%)\n",
            "Test accuracy: 8725/10000 (87.25%)\n",
            "Test accuracy: 55330/60000 (92.22%)\n",
            "Test accuracy: 9097/10000 (90.97%)\n",
            "Test accuracy: 53398/60000 (89.00%)\n",
            "Test accuracy: 8705/10000 (87.05%)\n",
            "Test accuracy: 56344/60000 (93.91%)\n",
            "Test accuracy: 9198/10000 (91.98%)\n",
            "Test accuracy: 58287/60000 (97.14%)\n",
            "Test accuracy: 9505/10000 (95.05%)\n",
            "Test accuracy: 58196/60000 (96.99%)\n",
            "Test accuracy: 9428/10000 (94.28%)\n",
            "Test accuracy: 58865/60000 (98.11%)\n",
            "Test accuracy: 9562/10000 (95.62%)\n",
            "Test accuracy: 59123/60000 (98.54%)\n",
            "Test accuracy: 9586/10000 (95.86%)\n",
            "Test accuracy: 54393/60000 (90.66%)\n",
            "Test accuracy: 8836/10000 (88.36%)\n",
            "Test accuracy: 56780/60000 (94.63%)\n",
            "Test accuracy: 9174/10000 (91.74%)\n",
            "Test accuracy: 58827/60000 (98.05%)\n",
            "Test accuracy: 9502/10000 (95.02%)\n",
            "Test accuracy: 55688/60000 (92.81%)\n",
            "Test accuracy: 8922/10000 (89.22%)\n",
            "Test accuracy: 59581/60000 (99.30%)\n",
            "Test accuracy: 9655/10000 (96.55%)\n",
            "Test accuracy: 57741/60000 (96.23%)\n",
            "Test accuracy: 9318/10000 (93.18%)\n",
            "Test accuracy: 58061/60000 (96.77%)\n",
            "Test accuracy: 9381/10000 (93.81%)\n",
            "Test accuracy: 55243/60000 (92.07%)\n",
            "Test accuracy: 8943/10000 (89.43%)\n",
            "Test accuracy: 58333/60000 (97.22%)\n",
            "Test accuracy: 9383/10000 (93.83%)\n",
            "Test accuracy: 59141/60000 (98.57%)\n",
            "Test accuracy: 9540/10000 (95.40%)\n",
            "Test accuracy: 59249/60000 (98.75%)\n",
            "Test accuracy: 9594/10000 (95.94%)\n",
            "Test accuracy: 59586/60000 (99.31%)\n",
            "Test accuracy: 9662/10000 (96.62%)\n",
            "Test accuracy: 59158/60000 (98.60%)\n",
            "Test accuracy: 9555/10000 (95.55%)\n",
            "Test accuracy: 59648/60000 (99.41%)\n",
            "Test accuracy: 9652/10000 (96.52%)\n",
            "Test accuracy: 59622/60000 (99.37%)\n",
            "Test accuracy: 9664/10000 (96.64%)\n",
            "Test accuracy: 59384/60000 (98.97%)\n",
            "Test accuracy: 9601/10000 (96.01%)\n",
            "Test accuracy: 59537/60000 (99.23%)\n",
            "Test accuracy: 9610/10000 (96.10%)\n",
            "Test accuracy: 59659/60000 (99.43%)\n",
            "Test accuracy: 9684/10000 (96.84%)\n",
            "Test accuracy: 59919/60000 (99.86%)\n",
            "Test accuracy: 9734/10000 (97.34%)\n",
            "Test accuracy: 59809/60000 (99.68%)\n",
            "Test accuracy: 9692/10000 (96.92%)\n",
            "Test accuracy: 58930/60000 (98.22%)\n",
            "Test accuracy: 9516/10000 (95.16%)\n",
            "Test accuracy: 59927/60000 (99.88%)\n",
            "Test accuracy: 9711/10000 (97.11%)\n",
            "Test accuracy: 59731/60000 (99.55%)\n",
            "Test accuracy: 9677/10000 (96.77%)\n",
            "Test accuracy: 59727/60000 (99.55%)\n",
            "Test accuracy: 9685/10000 (96.85%)\n",
            "Test accuracy: 59855/60000 (99.76%)\n",
            "Test accuracy: 9666/10000 (96.66%)\n",
            "Test accuracy: 59671/60000 (99.45%)\n",
            "Test accuracy: 9667/10000 (96.67%)\n",
            "Test accuracy: 59839/60000 (99.73%)\n",
            "Test accuracy: 9713/10000 (97.13%)\n",
            "Test accuracy: 59785/60000 (99.64%)\n",
            "Test accuracy: 9666/10000 (96.66%)\n",
            "Test accuracy: 59791/60000 (99.65%)\n",
            "Test accuracy: 9705/10000 (97.05%)\n",
            "Test accuracy: 59765/60000 (99.61%)\n",
            "Test accuracy: 9679/10000 (96.79%)\n",
            "Test accuracy: 59847/60000 (99.75%)\n",
            "Test accuracy: 9691/10000 (96.91%)\n",
            "Test accuracy: 59728/60000 (99.55%)\n",
            "Test accuracy: 9690/10000 (96.90%)\n",
            "Test accuracy: 57073/60000 (95.12%)\n",
            "Test accuracy: 9356/10000 (93.56%)\n",
            "Test accuracy: 58086/60000 (96.81%)\n",
            "Test accuracy: 9489/10000 (94.89%)\n",
            "Test accuracy: 58534/60000 (97.56%)\n",
            "Test accuracy: 9496/10000 (94.96%)\n",
            "Test accuracy: 58564/60000 (97.61%)\n",
            "Test accuracy: 9507/10000 (95.07%)\n",
            "Test accuracy: 59002/60000 (98.34%)\n",
            "Test accuracy: 9568/10000 (95.68%)\n",
            "Test accuracy: 59348/60000 (98.91%)\n",
            "Test accuracy: 9597/10000 (95.97%)\n",
            "Test accuracy: 58964/60000 (98.27%)\n",
            "Test accuracy: 9549/10000 (95.49%)\n",
            "Test accuracy: 59564/60000 (99.27%)\n",
            "Test accuracy: 9620/10000 (96.20%)\n",
            "Test accuracy: 59327/60000 (98.88%)\n",
            "Test accuracy: 9569/10000 (95.69%)\n",
            "Test accuracy: 59462/60000 (99.10%)\n",
            "Test accuracy: 9590/10000 (95.90%)\n",
            "Test accuracy: 59430/60000 (99.05%)\n",
            "Test accuracy: 9578/10000 (95.78%)\n",
            "Test accuracy: 59677/60000 (99.46%)\n",
            "Test accuracy: 9601/10000 (96.01%)\n",
            "Test accuracy: 59696/60000 (99.49%)\n",
            "Test accuracy: 9650/10000 (96.50%)\n",
            "Test accuracy: 59443/60000 (99.07%)\n",
            "Test accuracy: 9582/10000 (95.82%)\n",
            "Test accuracy: 59765/60000 (99.61%)\n",
            "Test accuracy: 9624/10000 (96.24%)\n",
            "Test accuracy: 59749/60000 (99.58%)\n",
            "Test accuracy: 9635/10000 (96.35%)\n",
            "Test accuracy: 59663/60000 (99.44%)\n",
            "Test accuracy: 9603/10000 (96.03%)\n",
            "Test accuracy: 59577/60000 (99.30%)\n",
            "Test accuracy: 9624/10000 (96.24%)\n",
            "Test accuracy: 59780/60000 (99.63%)\n",
            "Test accuracy: 9650/10000 (96.50%)\n",
            "Test accuracy: 59647/60000 (99.41%)\n",
            "Test accuracy: 9601/10000 (96.01%)\n",
            "Test accuracy: 59650/60000 (99.42%)\n",
            "Test accuracy: 9637/10000 (96.37%)\n",
            "Test accuracy: 59874/60000 (99.79%)\n",
            "Test accuracy: 9662/10000 (96.62%)\n",
            "Test accuracy: 59819/60000 (99.70%)\n",
            "Test accuracy: 9634/10000 (96.34%)\n",
            "Test accuracy: 59770/60000 (99.62%)\n",
            "Test accuracy: 9648/10000 (96.48%)\n",
            "Test accuracy: 59792/60000 (99.65%)\n",
            "Test accuracy: 9638/10000 (96.38%)\n",
            "Test accuracy: 59827/60000 (99.71%)\n",
            "Test accuracy: 9635/10000 (96.35%)\n",
            "Test accuracy: 59900/60000 (99.83%)\n",
            "Test accuracy: 9654/10000 (96.54%)\n",
            "Test accuracy: 59913/60000 (99.86%)\n",
            "Test accuracy: 9653/10000 (96.53%)\n",
            "Test accuracy: 59844/60000 (99.74%)\n",
            "Test accuracy: 9646/10000 (96.46%)\n",
            "Test accuracy: 59903/60000 (99.84%)\n",
            "Test accuracy: 9661/10000 (96.61%)\n",
            "Test accuracy: 59872/60000 (99.79%)\n",
            "Test accuracy: 9671/10000 (96.71%)\n",
            "Test accuracy: 59837/60000 (99.73%)\n",
            "Test accuracy: 9641/10000 (96.41%)\n",
            "Test accuracy: 59940/60000 (99.90%)\n",
            "Test accuracy: 9674/10000 (96.74%)\n",
            "Test accuracy: 59929/60000 (99.88%)\n",
            "Test accuracy: 9668/10000 (96.68%)\n",
            "Test accuracy: 59824/60000 (99.71%)\n",
            "Test accuracy: 9624/10000 (96.24%)\n",
            "Test accuracy: 59927/60000 (99.88%)\n",
            "Test accuracy: 9684/10000 (96.84%)\n",
            "Test accuracy: 59881/60000 (99.80%)\n",
            "Test accuracy: 9687/10000 (96.87%)\n",
            "Test accuracy: 59857/60000 (99.76%)\n",
            "Test accuracy: 9670/10000 (96.70%)\n",
            "Test accuracy: 59782/60000 (99.64%)\n",
            "Test accuracy: 9637/10000 (96.37%)\n",
            "Test accuracy: 59877/60000 (99.80%)\n",
            "Test accuracy: 9672/10000 (96.72%)\n",
            "Test accuracy: 57579/60000 (95.97%)\n",
            "Test accuracy: 9417/10000 (94.17%)\n",
            "Test accuracy: 58568/60000 (97.61%)\n",
            "Test accuracy: 9531/10000 (95.31%)\n",
            "Test accuracy: 58967/60000 (98.28%)\n",
            "Test accuracy: 9582/10000 (95.82%)\n",
            "Test accuracy: 59207/60000 (98.68%)\n",
            "Test accuracy: 9604/10000 (96.04%)\n",
            "Test accuracy: 59219/60000 (98.70%)\n",
            "Test accuracy: 9571/10000 (95.71%)\n",
            "Test accuracy: 59516/60000 (99.19%)\n",
            "Test accuracy: 9634/10000 (96.34%)\n",
            "Test accuracy: 59524/60000 (99.21%)\n",
            "Test accuracy: 9607/10000 (96.07%)\n",
            "Test accuracy: 59689/60000 (99.48%)\n",
            "Test accuracy: 9650/10000 (96.50%)\n",
            "Test accuracy: 59508/60000 (99.18%)\n",
            "Test accuracy: 9610/10000 (96.10%)\n",
            "Test accuracy: 59827/60000 (99.71%)\n",
            "Test accuracy: 9673/10000 (96.73%)\n",
            "Test accuracy: 59813/60000 (99.69%)\n",
            "Test accuracy: 9691/10000 (96.91%)\n",
            "Test accuracy: 59792/60000 (99.65%)\n",
            "Test accuracy: 9663/10000 (96.63%)\n",
            "Test accuracy: 59810/60000 (99.68%)\n",
            "Test accuracy: 9656/10000 (96.56%)\n",
            "Test accuracy: 59843/60000 (99.74%)\n",
            "Test accuracy: 9661/10000 (96.61%)\n",
            "Test accuracy: 59799/60000 (99.67%)\n",
            "Test accuracy: 9697/10000 (96.97%)\n",
            "Test accuracy: 59870/60000 (99.78%)\n",
            "Test accuracy: 9677/10000 (96.77%)\n",
            "Test accuracy: 59915/60000 (99.86%)\n",
            "Test accuracy: 9683/10000 (96.83%)\n",
            "Test accuracy: 59874/60000 (99.79%)\n",
            "Test accuracy: 9672/10000 (96.72%)\n",
            "Test accuracy: 59838/60000 (99.73%)\n",
            "Test accuracy: 9668/10000 (96.68%)\n",
            "Test accuracy: 59903/60000 (99.84%)\n",
            "Test accuracy: 9684/10000 (96.84%)\n",
            "Test accuracy: 59876/60000 (99.79%)\n",
            "Test accuracy: 9668/10000 (96.68%)\n",
            "Test accuracy: 59936/60000 (99.89%)\n",
            "Test accuracy: 9706/10000 (97.06%)\n",
            "Test accuracy: 59894/60000 (99.82%)\n",
            "Test accuracy: 9664/10000 (96.64%)\n",
            "Test accuracy: 59931/60000 (99.89%)\n",
            "Test accuracy: 9701/10000 (97.01%)\n",
            "Test accuracy: 59901/60000 (99.83%)\n",
            "Test accuracy: 9684/10000 (96.84%)\n",
            "Test accuracy: 59957/60000 (99.93%)\n",
            "Test accuracy: 9698/10000 (96.98%)\n",
            "Test accuracy: 59965/60000 (99.94%)\n",
            "Test accuracy: 9704/10000 (97.04%)\n",
            "Test accuracy: 59947/60000 (99.91%)\n",
            "Test accuracy: 9703/10000 (97.03%)\n",
            "Test accuracy: 59964/60000 (99.94%)\n",
            "Test accuracy: 9722/10000 (97.22%)\n",
            "Test accuracy: 59946/60000 (99.91%)\n",
            "Test accuracy: 9695/10000 (96.95%)\n",
            "Test accuracy: 59954/60000 (99.92%)\n",
            "Test accuracy: 9689/10000 (96.89%)\n",
            "Test accuracy: 59972/60000 (99.95%)\n",
            "Test accuracy: 9724/10000 (97.24%)\n",
            "Test accuracy: 59971/60000 (99.95%)\n",
            "Test accuracy: 9708/10000 (97.08%)\n",
            "Test accuracy: 59956/60000 (99.93%)\n",
            "Test accuracy: 9719/10000 (97.19%)\n",
            "Test accuracy: 59951/60000 (99.92%)\n",
            "Test accuracy: 9686/10000 (96.86%)\n",
            "Test accuracy: 59974/60000 (99.96%)\n",
            "Test accuracy: 9705/10000 (97.05%)\n",
            "Test accuracy: 59896/60000 (99.83%)\n",
            "Test accuracy: 9673/10000 (96.73%)\n",
            "Test accuracy: 59969/60000 (99.95%)\n",
            "Test accuracy: 9707/10000 (97.07%)\n",
            "Test accuracy: 59978/60000 (99.96%)\n",
            "Test accuracy: 9683/10000 (96.83%)\n",
            "Test accuracy: 59974/60000 (99.96%)\n",
            "Test accuracy: 9696/10000 (96.96%)\n",
            "Test accuracy: 57751/60000 (96.25%)\n",
            "Test accuracy: 9446/10000 (94.46%)\n",
            "Test accuracy: 58525/60000 (97.54%)\n",
            "Test accuracy: 9496/10000 (94.96%)\n",
            "Test accuracy: 59060/60000 (98.43%)\n",
            "Test accuracy: 9552/10000 (95.52%)\n",
            "Test accuracy: 59326/60000 (98.88%)\n",
            "Test accuracy: 9597/10000 (95.97%)\n",
            "Test accuracy: 59430/60000 (99.05%)\n",
            "Test accuracy: 9615/10000 (96.15%)\n",
            "Test accuracy: 59639/60000 (99.40%)\n",
            "Test accuracy: 9635/10000 (96.35%)\n",
            "Test accuracy: 59690/60000 (99.48%)\n",
            "Test accuracy: 9625/10000 (96.25%)\n",
            "Test accuracy: 59721/60000 (99.53%)\n",
            "Test accuracy: 9654/10000 (96.54%)\n",
            "Test accuracy: 59797/60000 (99.66%)\n",
            "Test accuracy: 9651/10000 (96.51%)\n",
            "Test accuracy: 59808/60000 (99.68%)\n",
            "Test accuracy: 9659/10000 (96.59%)\n",
            "Test accuracy: 59872/60000 (99.79%)\n",
            "Test accuracy: 9680/10000 (96.80%)\n",
            "Test accuracy: 59874/60000 (99.79%)\n",
            "Test accuracy: 9666/10000 (96.66%)\n",
            "Test accuracy: 59893/60000 (99.82%)\n",
            "Test accuracy: 9678/10000 (96.78%)\n",
            "Test accuracy: 59884/60000 (99.81%)\n",
            "Test accuracy: 9672/10000 (96.72%)\n",
            "Test accuracy: 59909/60000 (99.85%)\n",
            "Test accuracy: 9690/10000 (96.90%)\n",
            "Test accuracy: 59938/60000 (99.90%)\n",
            "Test accuracy: 9688/10000 (96.88%)\n",
            "Test accuracy: 59897/60000 (99.83%)\n",
            "Test accuracy: 9674/10000 (96.74%)\n",
            "Test accuracy: 59943/60000 (99.91%)\n",
            "Test accuracy: 9697/10000 (96.97%)\n",
            "Test accuracy: 59949/60000 (99.92%)\n",
            "Test accuracy: 9709/10000 (97.09%)\n",
            "Test accuracy: 59968/60000 (99.95%)\n",
            "Test accuracy: 9717/10000 (97.17%)\n",
            "Test accuracy: 59951/60000 (99.92%)\n",
            "Test accuracy: 9715/10000 (97.15%)\n",
            "Test accuracy: 59932/60000 (99.89%)\n",
            "Test accuracy: 9712/10000 (97.12%)\n",
            "Test accuracy: 59973/60000 (99.95%)\n",
            "Test accuracy: 9743/10000 (97.43%)\n",
            "Test accuracy: 59970/60000 (99.95%)\n",
            "Test accuracy: 9730/10000 (97.30%)\n",
            "Test accuracy: 59968/60000 (99.95%)\n",
            "Test accuracy: 9711/10000 (97.11%)\n",
            "Test accuracy: 59979/60000 (99.97%)\n",
            "Test accuracy: 9728/10000 (97.28%)\n",
            "Test accuracy: 59965/60000 (99.94%)\n",
            "Test accuracy: 9717/10000 (97.17%)\n",
            "Test accuracy: 59969/60000 (99.95%)\n",
            "Test accuracy: 9721/10000 (97.21%)\n",
            "Test accuracy: 59980/60000 (99.97%)\n",
            "Test accuracy: 9706/10000 (97.06%)\n",
            "Test accuracy: 59960/60000 (99.93%)\n",
            "Test accuracy: 9701/10000 (97.01%)\n",
            "Test accuracy: 59986/60000 (99.98%)\n",
            "Test accuracy: 9713/10000 (97.13%)\n",
            "Test accuracy: 59974/60000 (99.96%)\n",
            "Test accuracy: 9714/10000 (97.14%)\n",
            "Test accuracy: 59986/60000 (99.98%)\n",
            "Test accuracy: 9718/10000 (97.18%)\n",
            "Test accuracy: 59986/60000 (99.98%)\n",
            "Test accuracy: 9738/10000 (97.38%)\n",
            "Test accuracy: 59990/60000 (99.98%)\n",
            "Test accuracy: 9711/10000 (97.11%)\n",
            "Test accuracy: 59983/60000 (99.97%)\n",
            "Test accuracy: 9743/10000 (97.43%)\n",
            "Test accuracy: 59976/60000 (99.96%)\n",
            "Test accuracy: 9711/10000 (97.11%)\n",
            "Test accuracy: 59981/60000 (99.97%)\n",
            "Test accuracy: 9711/10000 (97.11%)\n",
            "Test accuracy: 59978/60000 (99.96%)\n",
            "Test accuracy: 9732/10000 (97.32%)\n",
            "Test accuracy: 59991/60000 (99.98%)\n",
            "Test accuracy: 9738/10000 (97.38%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aO7T286o8bki"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}